{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trees Iris h2o.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkRBA6cZwNzn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "caafee74-75c8-4949-f313-01fc3b12778e"
      },
      "source": [
        "! apt-get install default-jre\n",
        "!java -version\n",
        "! pip install h2o\n",
        "import h2o\n",
        "h2o.init()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "default-jre is already the newest version (2:1.11-68ubuntu1~18.04.1).\n",
            "default-jre set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded.\n",
            "openjdk version \"11.0.4\" 2019-07-16\n",
            "OpenJDK Runtime Environment (build 11.0.4+11-post-Ubuntu-1ubuntu218.04.3)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.4+11-post-Ubuntu-1ubuntu218.04.3, mixed mode, sharing)\n",
            "Collecting h2o\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/d1/aaa74df4716b2454d6034261807ef3855d014862c801f0e9b803b568006d/h2o-3.28.0.1.tar.gz (123.4MB)\n",
            "\u001b[K     |████████████████████████████████| 123.4MB 36kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from h2o) (2.21.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from h2o) (0.8.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from h2o) (0.16.0)\n",
            "Collecting colorama>=0.3.8\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (3.0.4)\n",
            "Building wheels for collected packages: h2o\n",
            "  Building wheel for h2o (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for h2o: filename=h2o-3.28.0.1-py2.py3-none-any.whl size=123410554 sha256=2dd0bf9ee58bde530af40f9f05938da6fa8c1f86213233943133deb66a8b97ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/ff/82/f4/3fe9c895b93c53b25ae44dc44aa54dad571c711f48bc485fe9\n",
            "Successfully built h2o\n",
            "Installing collected packages: colorama, h2o\n",
            "Successfully installed colorama-0.4.3 h2o-3.28.0.1\n",
            "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
            "Attempting to start a local H2O server...\n",
            "  Java Version: openjdk version \"11.0.4\" 2019-07-16; OpenJDK Runtime Environment (build 11.0.4+11-post-Ubuntu-1ubuntu218.04.3); OpenJDK 64-Bit Server VM (build 11.0.4+11-post-Ubuntu-1ubuntu218.04.3, mixed mode, sharing)\n",
            "  Starting server from /usr/local/lib/python3.6/dist-packages/h2o/backend/bin/h2o.jar\n",
            "  Ice root: /tmp/tmpiokg7byw\n",
            "  JVM stdout: /tmp/tmpiokg7byw/h2o_unknownUser_started_from_python.out\n",
            "  JVM stderr: /tmp/tmpiokg7byw/h2o_unknownUser_started_from_python.err\n",
            "  Server is running at http://127.0.0.1:54321\n",
            "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
              "<td>02 secs</td></tr>\n",
              "<tr><td>H2O cluster timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O data parsing timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O cluster version:</td>\n",
              "<td>3.28.0.1</td></tr>\n",
              "<tr><td>H2O cluster version age:</td>\n",
              "<td>2 days </td></tr>\n",
              "<tr><td>H2O cluster name:</td>\n",
              "<td>H2O_from_python_unknownUser_wsrv28</td></tr>\n",
              "<tr><td>H2O cluster total nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O cluster free memory:</td>\n",
              "<td>3 Gb</td></tr>\n",
              "<tr><td>H2O cluster total cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O cluster allowed cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O cluster status:</td>\n",
              "<td>accepting new members, healthy</td></tr>\n",
              "<tr><td>H2O connection url:</td>\n",
              "<td>http://127.0.0.1:54321</td></tr>\n",
              "<tr><td>H2O connection proxy:</td>\n",
              "<td>{'http': None, 'https': None}</td></tr>\n",
              "<tr><td>H2O internal security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>H2O API Extensions:</td>\n",
              "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
              "<tr><td>Python version:</td>\n",
              "<td>3.6.9 final</td></tr></table></div>"
            ],
            "text/plain": [
              "--------------------------  ------------------------------------------------------------------\n",
              "H2O cluster uptime:         02 secs\n",
              "H2O cluster timezone:       Etc/UTC\n",
              "H2O data parsing timezone:  UTC\n",
              "H2O cluster version:        3.28.0.1\n",
              "H2O cluster version age:    2 days\n",
              "H2O cluster name:           H2O_from_python_unknownUser_wsrv28\n",
              "H2O cluster total nodes:    1\n",
              "H2O cluster free memory:    3 Gb\n",
              "H2O cluster total cores:    2\n",
              "H2O cluster allowed cores:  2\n",
              "H2O cluster status:         accepting new members, healthy\n",
              "H2O connection url:         http://127.0.0.1:54321\n",
              "H2O connection proxy:       {'http': None, 'https': None}\n",
              "H2O internal security:      False\n",
              "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
              "Python version:             3.6.9 final\n",
              "--------------------------  ------------------------------------------------------------------"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a48nz2vtwgOZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "2cd74e9f-1543-451e-deab-0a66f3efcd76"
      },
      "source": [
        "url = 'http://h2o-public-test-data.s3.amazonaws.com/smalldata/iris/iris_wheader.csv'\n",
        "iris = h2o.import_file(url)\n",
        "train, test = iris.split_frame([0.8])\n",
        "train.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table>\n",
              "<thead>\n",
              "<tr><th>       </th><th>sepal_len         </th><th>sepal_wid          </th><th>petal_len         </th><th>petal_wid         </th><th>class      </th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>type   </td><td>real              </td><td>real               </td><td>real              </td><td>real              </td><td>enum       </td></tr>\n",
              "<tr><td>mins   </td><td>4.3               </td><td>2.0                </td><td>1.1               </td><td>0.1               </td><td>           </td></tr>\n",
              "<tr><td>mean   </td><td>5.759322033898303 </td><td>3.074576271186441  </td><td>3.556779661016949 </td><td>1.122881355932203 </td><td>           </td></tr>\n",
              "<tr><td>maxs   </td><td>7.9               </td><td>4.4                </td><td>6.7               </td><td>2.5               </td><td>           </td></tr>\n",
              "<tr><td>sigma  </td><td>0.7693084127119191</td><td>0.45501694167350376</td><td>1.7356236748729184</td><td>0.7598257804079201</td><td>           </td></tr>\n",
              "<tr><td>zeros  </td><td>0                 </td><td>0                  </td><td>0                 </td><td>0                 </td><td>           </td></tr>\n",
              "<tr><td>missing</td><td>0                 </td><td>0                  </td><td>0                 </td><td>0                 </td><td>0          </td></tr>\n",
              "<tr><td>0      </td><td>5.1               </td><td>3.5                </td><td>1.4               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
              "<tr><td>1      </td><td>4.9               </td><td>3.0                </td><td>1.4               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
              "<tr><td>2      </td><td>4.7               </td><td>3.2                </td><td>1.3               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
              "<tr><td>3      </td><td>5.0               </td><td>3.6                </td><td>1.4               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
              "<tr><td>4      </td><td>5.4               </td><td>3.9                </td><td>1.7               </td><td>0.4               </td><td>Iris-setosa</td></tr>\n",
              "<tr><td>5      </td><td>4.6               </td><td>3.4                </td><td>1.4               </td><td>0.3               </td><td>Iris-setosa</td></tr>\n",
              "<tr><td>6      </td><td>5.0               </td><td>3.4                </td><td>1.5               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
              "<tr><td>7      </td><td>4.4               </td><td>2.9                </td><td>1.4               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
              "<tr><td>8      </td><td>4.9               </td><td>3.1                </td><td>1.5               </td><td>0.1               </td><td>Iris-setosa</td></tr>\n",
              "<tr><td>9      </td><td>5.4               </td><td>3.7                </td><td>1.5               </td><td>0.2               </td><td>Iris-setosa</td></tr>\n",
              "</tbody>\n",
              "</table>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19jsdO-C7Rse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f23132e-4399-4c59-a9a0-4c3be01f9fda"
      },
      "source": [
        "train.nrows"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxbaJjuc7VbQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d631196-daa6-48fc-dbd4-5aabf80ca408"
      },
      "source": [
        "test.nrows"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHmd6cPG7XJ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c83f517d-604a-40df-ee1c-650245cb6185"
      },
      "source": [
        "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
        "\n",
        "rf = H2ORandomForestEstimator()\n",
        "rf.train(['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid'], 'class', train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drf Model Build progress: |███████████████████████████████████████████████| 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTjGw5-F72c7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a9a6f07a-545d-4112-db91-6eba4c378f0c"
      },
      "source": [
        "rf"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Details\n",
            "=============\n",
            "H2ORandomForestEstimator :  Distributed Random Forest\n",
            "Model Key:  DRF_model_python_1576770891108_1\n",
            "\n",
            "\n",
            "Model Summary: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>number_of_trees</th>\n",
              "      <th>number_of_internal_trees</th>\n",
              "      <th>model_size_in_bytes</th>\n",
              "      <th>min_depth</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>mean_depth</th>\n",
              "      <th>min_leaves</th>\n",
              "      <th>max_leaves</th>\n",
              "      <th>mean_leaves</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>50.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>19791.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>5.86</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     number_of_trees  ...  max_leaves  mean_leaves\n",
              "0               50.0  ...        12.0         5.86\n",
              "\n",
              "[1 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "ModelMetricsMultinomial: drf\n",
            "** Reported on train data. **\n",
            "\n",
            "MSE: 0.037246799681345456\n",
            "RMSE: 0.19299429960842227\n",
            "LogLoss: 0.11635619778386756\n",
            "Mean Per-Class Error: 0.054411764705882354\n",
            "\n",
            "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iris-setosa</th>\n",
              "      <th>Iris-versicolor</th>\n",
              "      <th>Iris-virginica</th>\n",
              "      <th>Error</th>\n",
              "      <th>Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>44.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0 / 44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>3 / 40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.088235</td>\n",
              "      <td>3 / 34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.050847</td>\n",
              "      <td>6 / 118</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Iris-setosa  Iris-versicolor  Iris-virginica     Error     Rate\n",
              "0         44.0              0.0             0.0  0.000000   0 / 44\n",
              "1          0.0             37.0             3.0  0.075000   3 / 40\n",
              "2          0.0              3.0            31.0  0.088235   3 / 34\n",
              "3         44.0             40.0            34.0  0.050847  6 / 118"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Top-3 Hit Ratios: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>k</th>\n",
              "      <th>hit_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.949152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   k  hit_ratio\n",
              "0  1   0.949152\n",
              "1  2   1.000000\n",
              "2  3   1.000000"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Scoring History: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>duration</th>\n",
              "      <th>number_of_trees</th>\n",
              "      <th>training_rmse</th>\n",
              "      <th>training_logloss</th>\n",
              "      <th>training_classification_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:25</td>\n",
              "      <td>0.045 sec</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:25</td>\n",
              "      <td>0.251 sec</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.204124</td>\n",
              "      <td>1.174397</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:25</td>\n",
              "      <td>0.287 sec</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.330314</td>\n",
              "      <td>3.267141</td>\n",
              "      <td>0.107692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:25</td>\n",
              "      <td>0.309 sec</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.321642</td>\n",
              "      <td>2.526799</td>\n",
              "      <td>0.116279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:25</td>\n",
              "      <td>0.332 sec</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.313352</td>\n",
              "      <td>2.517839</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:25</td>\n",
              "      <td>0.353 sec</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.263884</td>\n",
              "      <td>1.681193</td>\n",
              "      <td>0.074766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:25</td>\n",
              "      <td>0.368 sec</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.246968</td>\n",
              "      <td>1.317965</td>\n",
              "      <td>0.072072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:25</td>\n",
              "      <td>0.392 sec</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.231346</td>\n",
              "      <td>0.995268</td>\n",
              "      <td>0.061947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:25</td>\n",
              "      <td>0.424 sec</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.232993</td>\n",
              "      <td>0.976424</td>\n",
              "      <td>0.060345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:25</td>\n",
              "      <td>0.442 sec</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.211763</td>\n",
              "      <td>0.667839</td>\n",
              "      <td>0.050847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:25</td>\n",
              "      <td>0.476 sec</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.183301</td>\n",
              "      <td>0.097681</td>\n",
              "      <td>0.050847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:25</td>\n",
              "      <td>0.511 sec</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.186972</td>\n",
              "      <td>0.100497</td>\n",
              "      <td>0.050847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:26</td>\n",
              "      <td>0.576 sec</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.190134</td>\n",
              "      <td>0.104601</td>\n",
              "      <td>0.059322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:26</td>\n",
              "      <td>0.602 sec</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.187553</td>\n",
              "      <td>0.104963</td>\n",
              "      <td>0.050847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:26</td>\n",
              "      <td>0.625 sec</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.188548</td>\n",
              "      <td>0.105106</td>\n",
              "      <td>0.050847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:26</td>\n",
              "      <td>0.640 sec</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.185055</td>\n",
              "      <td>0.102229</td>\n",
              "      <td>0.050847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:26</td>\n",
              "      <td>0.662 sec</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.183068</td>\n",
              "      <td>0.100809</td>\n",
              "      <td>0.042373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:26</td>\n",
              "      <td>0.690 sec</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.182282</td>\n",
              "      <td>0.102681</td>\n",
              "      <td>0.050847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:26</td>\n",
              "      <td>0.714 sec</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.181320</td>\n",
              "      <td>0.101372</td>\n",
              "      <td>0.050847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:13:26</td>\n",
              "      <td>0.738 sec</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.184499</td>\n",
              "      <td>0.104196</td>\n",
              "      <td>0.050847</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                timestamp  ... training_logloss  training_classification_error\n",
              "0     2019-12-19 16:13:25  ...              NaN                            NaN\n",
              "1     2019-12-19 16:13:25  ...         1.174397                       0.066667\n",
              "2     2019-12-19 16:13:25  ...         3.267141                       0.107692\n",
              "3     2019-12-19 16:13:25  ...         2.526799                       0.116279\n",
              "4     2019-12-19 16:13:25  ...         2.517839                       0.100000\n",
              "5     2019-12-19 16:13:25  ...         1.681193                       0.074766\n",
              "6     2019-12-19 16:13:25  ...         1.317965                       0.072072\n",
              "7     2019-12-19 16:13:25  ...         0.995268                       0.061947\n",
              "8     2019-12-19 16:13:25  ...         0.976424                       0.060345\n",
              "9     2019-12-19 16:13:25  ...         0.667839                       0.050847\n",
              "10    2019-12-19 16:13:25  ...         0.097681                       0.050847\n",
              "11    2019-12-19 16:13:25  ...         0.100497                       0.050847\n",
              "12    2019-12-19 16:13:26  ...         0.104601                       0.059322\n",
              "13    2019-12-19 16:13:26  ...         0.104963                       0.050847\n",
              "14    2019-12-19 16:13:26  ...         0.105106                       0.050847\n",
              "15    2019-12-19 16:13:26  ...         0.102229                       0.050847\n",
              "16    2019-12-19 16:13:26  ...         0.100809                       0.042373\n",
              "17    2019-12-19 16:13:26  ...         0.102681                       0.050847\n",
              "18    2019-12-19 16:13:26  ...         0.101372                       0.050847\n",
              "19    2019-12-19 16:13:26  ...         0.104196                       0.050847\n",
              "\n",
              "[20 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "See the whole table with table.as_data_frame()\n",
            "\n",
            "Variable Importances: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>variable</th>\n",
              "      <th>relative_importance</th>\n",
              "      <th>scaled_importance</th>\n",
              "      <th>percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>petal_len</td>\n",
              "      <td>1887.131592</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.549145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>petal_wid</td>\n",
              "      <td>1238.884888</td>\n",
              "      <td>0.656491</td>\n",
              "      <td>0.360508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sepal_len</td>\n",
              "      <td>233.669525</td>\n",
              "      <td>0.123823</td>\n",
              "      <td>0.067997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sepal_wid</td>\n",
              "      <td>76.807076</td>\n",
              "      <td>0.040700</td>\n",
              "      <td>0.022350</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    variable  relative_importance  scaled_importance  percentage\n",
              "0  petal_len          1887.131592           1.000000    0.549145\n",
              "1  petal_wid          1238.884888           0.656491    0.360508\n",
              "2  sepal_len           233.669525           0.123823    0.067997\n",
              "3  sepal_wid            76.807076           0.040700    0.022350"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD67AAf276Nm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "408a92b8-0532-4b50-d157-83712d9f7a50"
      },
      "source": [
        "rf.predict(test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drf prediction progress: |████████████████████████████████████████████████| 100%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table>\n",
              "<thead>\n",
              "<tr><th>predict        </th><th style=\"text-align: right;\">  Iris-setosa</th><th style=\"text-align: right;\">  Iris-versicolor</th><th style=\"text-align: right;\">  Iris-virginica</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>Iris-setosa    </td><td style=\"text-align: right;\">     0.997276</td><td style=\"text-align: right;\">         0       </td><td style=\"text-align: right;\">      0.00272376</td></tr>\n",
              "<tr><td>Iris-setosa    </td><td style=\"text-align: right;\">     0.997276</td><td style=\"text-align: right;\">         0       </td><td style=\"text-align: right;\">      0.00272376</td></tr>\n",
              "<tr><td>Iris-setosa    </td><td style=\"text-align: right;\">     0.997276</td><td style=\"text-align: right;\">         0       </td><td style=\"text-align: right;\">      0.00272376</td></tr>\n",
              "<tr><td>Iris-setosa    </td><td style=\"text-align: right;\">     0.997276</td><td style=\"text-align: right;\">         0       </td><td style=\"text-align: right;\">      0.00272376</td></tr>\n",
              "<tr><td>Iris-setosa    </td><td style=\"text-align: right;\">     0.997276</td><td style=\"text-align: right;\">         0       </td><td style=\"text-align: right;\">      0.00272376</td></tr>\n",
              "<tr><td>Iris-setosa    </td><td style=\"text-align: right;\">     0.997276</td><td style=\"text-align: right;\">         0       </td><td style=\"text-align: right;\">      0.00272376</td></tr>\n",
              "<tr><td>Iris-versicolor</td><td style=\"text-align: right;\">     0       </td><td style=\"text-align: right;\">         0.997276</td><td style=\"text-align: right;\">      0.00272376</td></tr>\n",
              "<tr><td>Iris-versicolor</td><td style=\"text-align: right;\">     0       </td><td style=\"text-align: right;\">         0.997103</td><td style=\"text-align: right;\">      0.00289711</td></tr>\n",
              "<tr><td>Iris-versicolor</td><td style=\"text-align: right;\">     0       </td><td style=\"text-align: right;\">         0.949294</td><td style=\"text-align: right;\">      0.0507056 </td></tr>\n",
              "<tr><td>Iris-versicolor</td><td style=\"text-align: right;\">     0       </td><td style=\"text-align: right;\">         0.997276</td><td style=\"text-align: right;\">      0.00272376</td></tr>\n",
              "</tbody>\n",
              "</table>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoPqHXHH8HhU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "646079fb-7412-4bfe-ab6d-5878b6cbeba8"
      },
      "source": [
        "rf.model_performance(test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ModelMetricsMultinomial: drf\n",
            "** Reported on test data. **\n",
            "\n",
            "MSE: 0.021168639742425267\n",
            "RMSE: 0.1454944663635881\n",
            "LogLoss: 0.06516357950274529\n",
            "Mean Per-Class Error: 0.020833333333333332\n",
            "\n",
            "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iris-setosa</th>\n",
              "      <th>Iris-versicolor</th>\n",
              "      <th>Iris-virginica</th>\n",
              "      <th>Error</th>\n",
              "      <th>Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0 / 6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0 / 10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.06250</td>\n",
              "      <td>1 / 16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.03125</td>\n",
              "      <td>1 / 32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Iris-setosa  Iris-versicolor  Iris-virginica    Error    Rate\n",
              "0          6.0              0.0             0.0  0.00000   0 / 6\n",
              "1          0.0             10.0             0.0  0.00000  0 / 10\n",
              "2          0.0              1.0            15.0  0.06250  1 / 16\n",
              "3          6.0             11.0            15.0  0.03125  1 / 32"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Top-3 Hit Ratios: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>k</th>\n",
              "      <th>hit_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.96875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   k  hit_ratio\n",
              "0  1    0.96875\n",
              "1  2    1.00000\n",
              "2  3    1.00000"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is425eOU9S6W",
        "colab_type": "text"
      },
      "source": [
        "### Now using Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuCnEnRV82iB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96f134a0-ad49-4c82-b165-85356607853b"
      },
      "source": [
        "from h2o.estimators.gbm import H2OGradientBoostingEstimator as gb\n",
        "\n",
        "gbe = gb()\n",
        "gbe.train(['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid'], 'class', train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6hVG3yN9q5d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4c4f5ebf-65e9-41f3-866d-2b8866a92fbc"
      },
      "source": [
        "gbe"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Details\n",
            "=============\n",
            "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
            "Model Key:  GBM_model_python_1576770891108_2\n",
            "\n",
            "\n",
            "Model Summary: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>number_of_trees</th>\n",
              "      <th>number_of_internal_trees</th>\n",
              "      <th>model_size_in_bytes</th>\n",
              "      <th>min_depth</th>\n",
              "      <th>max_depth</th>\n",
              "      <th>mean_depth</th>\n",
              "      <th>min_leaves</th>\n",
              "      <th>max_leaves</th>\n",
              "      <th>mean_leaves</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>50.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>24182.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.62</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.186666</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     number_of_trees  ...  max_leaves  mean_leaves\n",
              "0               50.0  ...        10.0     8.186666\n",
              "\n",
              "[1 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "ModelMetricsMultinomial: gbm\n",
            "** Reported on train data. **\n",
            "\n",
            "MSE: 0.001418114378100915\n",
            "RMSE: 0.037657859446613734\n",
            "LogLoss: 0.015027093410516976\n",
            "Mean Per-Class Error: 0.0\n",
            "\n",
            "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iris-setosa</th>\n",
              "      <th>Iris-versicolor</th>\n",
              "      <th>Iris-virginica</th>\n",
              "      <th>Error</th>\n",
              "      <th>Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>44.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0 / 44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0 / 40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0 / 34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0 / 118</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Iris-setosa  Iris-versicolor  Iris-virginica  Error     Rate\n",
              "0         44.0              0.0             0.0    0.0   0 / 44\n",
              "1          0.0             40.0             0.0    0.0   0 / 40\n",
              "2          0.0              0.0            34.0    0.0   0 / 34\n",
              "3         44.0             40.0            34.0    0.0  0 / 118"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Top-3 Hit Ratios: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>k</th>\n",
              "      <th>hit_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   k  hit_ratio\n",
              "0  1        1.0\n",
              "1  2        1.0\n",
              "2  3        1.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Scoring History: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>duration</th>\n",
              "      <th>number_of_trees</th>\n",
              "      <th>training_rmse</th>\n",
              "      <th>training_logloss</th>\n",
              "      <th>training_classification_error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.007 sec</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>0.644068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.077 sec</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.604257</td>\n",
              "      <td>0.927389</td>\n",
              "      <td>0.050847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.101 sec</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.547714</td>\n",
              "      <td>0.794450</td>\n",
              "      <td>0.042373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.112 sec</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.496117</td>\n",
              "      <td>0.686535</td>\n",
              "      <td>0.050847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.124 sec</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.450085</td>\n",
              "      <td>0.598705</td>\n",
              "      <td>0.050847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.136 sec</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.409100</td>\n",
              "      <td>0.525703</td>\n",
              "      <td>0.050847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.147 sec</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.372625</td>\n",
              "      <td>0.463944</td>\n",
              "      <td>0.050847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.159 sec</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.338615</td>\n",
              "      <td>0.408734</td>\n",
              "      <td>0.050847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.171 sec</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.309144</td>\n",
              "      <td>0.362578</td>\n",
              "      <td>0.050847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.183 sec</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.281383</td>\n",
              "      <td>0.320493</td>\n",
              "      <td>0.033898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.195 sec</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.257309</td>\n",
              "      <td>0.284682</td>\n",
              "      <td>0.025424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.207 sec</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.236575</td>\n",
              "      <td>0.254080</td>\n",
              "      <td>0.025424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.220 sec</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.220693</td>\n",
              "      <td>0.230174</td>\n",
              "      <td>0.025424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.230 sec</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.205053</td>\n",
              "      <td>0.206930</td>\n",
              "      <td>0.016949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.243 sec</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.191851</td>\n",
              "      <td>0.186935</td>\n",
              "      <td>0.025424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.258 sec</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.180787</td>\n",
              "      <td>0.169680</td>\n",
              "      <td>0.025424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.270 sec</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.170732</td>\n",
              "      <td>0.154161</td>\n",
              "      <td>0.025424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.281 sec</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.163175</td>\n",
              "      <td>0.141928</td>\n",
              "      <td>0.025424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.292 sec</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.155779</td>\n",
              "      <td>0.129999</td>\n",
              "      <td>0.025424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td></td>\n",
              "      <td>2019-12-19 16:21:22</td>\n",
              "      <td>0.304 sec</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.149570</td>\n",
              "      <td>0.119601</td>\n",
              "      <td>0.025424</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                timestamp  ... training_logloss  training_classification_error\n",
              "0     2019-12-19 16:21:22  ...         1.098612                       0.644068\n",
              "1     2019-12-19 16:21:22  ...         0.927389                       0.050847\n",
              "2     2019-12-19 16:21:22  ...         0.794450                       0.042373\n",
              "3     2019-12-19 16:21:22  ...         0.686535                       0.050847\n",
              "4     2019-12-19 16:21:22  ...         0.598705                       0.050847\n",
              "5     2019-12-19 16:21:22  ...         0.525703                       0.050847\n",
              "6     2019-12-19 16:21:22  ...         0.463944                       0.050847\n",
              "7     2019-12-19 16:21:22  ...         0.408734                       0.050847\n",
              "8     2019-12-19 16:21:22  ...         0.362578                       0.050847\n",
              "9     2019-12-19 16:21:22  ...         0.320493                       0.033898\n",
              "10    2019-12-19 16:21:22  ...         0.284682                       0.025424\n",
              "11    2019-12-19 16:21:22  ...         0.254080                       0.025424\n",
              "12    2019-12-19 16:21:22  ...         0.230174                       0.025424\n",
              "13    2019-12-19 16:21:22  ...         0.206930                       0.016949\n",
              "14    2019-12-19 16:21:22  ...         0.186935                       0.025424\n",
              "15    2019-12-19 16:21:22  ...         0.169680                       0.025424\n",
              "16    2019-12-19 16:21:22  ...         0.154161                       0.025424\n",
              "17    2019-12-19 16:21:22  ...         0.141928                       0.025424\n",
              "18    2019-12-19 16:21:22  ...         0.129999                       0.025424\n",
              "19    2019-12-19 16:21:22  ...         0.119601                       0.025424\n",
              "\n",
              "[20 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "See the whole table with table.as_data_frame()\n",
            "\n",
            "Variable Importances: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>variable</th>\n",
              "      <th>relative_importance</th>\n",
              "      <th>scaled_importance</th>\n",
              "      <th>percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>petal_wid</td>\n",
              "      <td>217.684692</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.605573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>petal_len</td>\n",
              "      <td>137.851944</td>\n",
              "      <td>0.633264</td>\n",
              "      <td>0.383488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sepal_len</td>\n",
              "      <td>2.012470</td>\n",
              "      <td>0.009245</td>\n",
              "      <td>0.005598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sepal_wid</td>\n",
              "      <td>1.919837</td>\n",
              "      <td>0.008819</td>\n",
              "      <td>0.005341</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    variable  relative_importance  scaled_importance  percentage\n",
              "0  petal_wid           217.684692           1.000000    0.605573\n",
              "1  petal_len           137.851944           0.633264    0.383488\n",
              "2  sepal_len             2.012470           0.009245    0.005598\n",
              "3  sepal_wid             1.919837           0.008819    0.005341"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AshBzjO9uU9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "outputId": "8a8b207e-2e98-4ee5-f41a-e26795c8067b"
      },
      "source": [
        "gbe.predict(test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table>\n",
              "<thead>\n",
              "<tr><th>predict        </th><th style=\"text-align: right;\">  Iris-setosa</th><th style=\"text-align: right;\">  Iris-versicolor</th><th style=\"text-align: right;\">  Iris-virginica</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>Iris-setosa    </td><td style=\"text-align: right;\">  0.998931   </td><td style=\"text-align: right;\">      0.00039064 </td><td style=\"text-align: right;\">     0.000678286</td></tr>\n",
              "<tr><td>Iris-setosa    </td><td style=\"text-align: right;\">  0.998812   </td><td style=\"text-align: right;\">      0.000390689</td><td style=\"text-align: right;\">     0.000796973</td></tr>\n",
              "<tr><td>Iris-setosa    </td><td style=\"text-align: right;\">  0.997246   </td><td style=\"text-align: right;\">      0.00223878 </td><td style=\"text-align: right;\">     0.00051493 </td></tr>\n",
              "<tr><td>Iris-setosa    </td><td style=\"text-align: right;\">  0.998931   </td><td style=\"text-align: right;\">      0.000390527</td><td style=\"text-align: right;\">     0.000678091</td></tr>\n",
              "<tr><td>Iris-setosa    </td><td style=\"text-align: right;\">  0.998341   </td><td style=\"text-align: right;\">      0.00114306 </td><td style=\"text-align: right;\">     0.000515737</td></tr>\n",
              "<tr><td>Iris-setosa    </td><td style=\"text-align: right;\">  0.998931   </td><td style=\"text-align: right;\">      0.000390794</td><td style=\"text-align: right;\">     0.000678616</td></tr>\n",
              "<tr><td>Iris-versicolor</td><td style=\"text-align: right;\">  0.00166089 </td><td style=\"text-align: right;\">      0.994238   </td><td style=\"text-align: right;\">     0.00410113 </td></tr>\n",
              "<tr><td>Iris-versicolor</td><td style=\"text-align: right;\">  0.0024919  </td><td style=\"text-align: right;\">      0.986984   </td><td style=\"text-align: right;\">     0.0105241  </td></tr>\n",
              "<tr><td>Iris-versicolor</td><td style=\"text-align: right;\">  0.0301906  </td><td style=\"text-align: right;\">      0.85561    </td><td style=\"text-align: right;\">     0.1142     </td></tr>\n",
              "<tr><td>Iris-versicolor</td><td style=\"text-align: right;\">  0.000652859</td><td style=\"text-align: right;\">      0.997622   </td><td style=\"text-align: right;\">     0.00172534 </td></tr>\n",
              "</tbody>\n",
              "</table>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1PmDx_T9xuH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "d9e6d91e-aac0-49af-9b11-4d121a860a86"
      },
      "source": [
        "gbe.model_performance(test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ModelMetricsMultinomial: gbm\n",
            "** Reported on test data. **\n",
            "\n",
            "MSE: 0.030850346160680865\n",
            "RMSE: 0.17564266611697987\n",
            "LogLoss: 0.13521566708126162\n",
            "Mean Per-Class Error: 0.020833333333333332\n",
            "\n",
            "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iris-setosa</th>\n",
              "      <th>Iris-versicolor</th>\n",
              "      <th>Iris-virginica</th>\n",
              "      <th>Error</th>\n",
              "      <th>Rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0 / 6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0 / 10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.06250</td>\n",
              "      <td>1 / 16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.03125</td>\n",
              "      <td>1 / 32</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Iris-setosa  Iris-versicolor  Iris-virginica    Error    Rate\n",
              "0          6.0              0.0             0.0  0.00000   0 / 6\n",
              "1          0.0             10.0             0.0  0.00000  0 / 10\n",
              "2          0.0              1.0            15.0  0.06250  1 / 16\n",
              "3          6.0             11.0            15.0  0.03125  1 / 32"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Top-3 Hit Ratios: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>k</th>\n",
              "      <th>hit_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.96875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   k  hit_ratio\n",
              "0  1    0.96875\n",
              "1  2    1.00000\n",
              "2  3    1.00000"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yroj7W0m91OE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41e071de-b8b0-434f-c438-582a96c39222"
      },
      "source": [
        "help(gb)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on class H2OGradientBoostingEstimator in module h2o.estimators.gbm:\n",
            "\n",
            "class H2OGradientBoostingEstimator(h2o.estimators.estimator_base.H2OEstimator)\n",
            " |  Gradient Boosting Machine\n",
            " |  \n",
            " |  Builds gradient boosted trees on a parsed data set, for regression or classification.\n",
            " |  The default distribution function will guess the model type based on the response column type.\n",
            " |  Otherwise, the response column must be an enum for \"bernoulli\" or \"multinomial\", and numeric\n",
            " |  for all other distributions.\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      H2OGradientBoostingEstimator\n",
            " |      h2o.estimators.estimator_base.H2OEstimator\n",
            " |      h2o.model.model_base.ModelBase\n",
            " |      h2o.model.model_base.ModelBase\n",
            " |      h2o.base.Keyed\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, **kwargs)\n",
            " |      Construct a new model instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  balance_classes\n",
            " |      Balance training data class counts via over/under-sampling (for imbalanced data).\n",
            " |      \n",
            " |      Type: ``bool``  (default: ``False``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> covtype = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/covtype/covtype.20k.data\")\n",
            " |      >>> covtype[54] = covtype[54].asfactor()\n",
            " |      >>> predictors = covtype.columns[0:54]\n",
            " |      >>> response = 'C55'\n",
            " |      >>> train, valid = covtype.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> cov_gbm = H2OGradientBoostingEstimator(balance_classes=True,\n",
            " |      ...                                        seed=1234)\n",
            " |      >>> cov_gbm.train(x=predictors,\n",
            " |      ...               y=response,\n",
            " |      ...               training_frame=train,\n",
            " |      ...               validation_frame=valid)\n",
            " |      >>> cov_gbm.logloss(valid=True)\n",
            " |  \n",
            " |  build_tree_one_node\n",
            " |      Run on one node only; no network overhead but fewer cpus used.  Suitable for small datasets.\n",
            " |      \n",
            " |      Type: ``bool``  (default: ``False``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
            " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
            " |      >>> response = \"economy_20mpg\"\n",
            " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(build_tree_one_node=True,\n",
            " |      ...                                         seed=1234)\n",
            " |      >>> cars_gbm.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=train,\n",
            " |      ...                validation_frame=valid)\n",
            " |      >>> cars_gbm.auc(valid=True)\n",
            " |  \n",
            " |  calibrate_model\n",
            " |      Use Platt Scaling to calculate calibrated class probabilities. Calibration can provide more accurate estimates\n",
            " |      of class probabilities.\n",
            " |      \n",
            " |      Type: ``bool``  (default: ``False``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> ecology = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/ecology_model.csv\")\n",
            " |      >>> ecology['Angaus'] = ecology['Angaus'].asfactor()\n",
            " |      >>> response = 'Angaus'\n",
            " |      >>> train, calib = ecology.split_frame(seed = 12354)\n",
            " |      >>> predictors = ecology.columns[3:13]\n",
            " |      >>> w = h2o.create_frame(binary_fraction=1,\n",
            " |      ...                      binary_ones_fraction=0.5,\n",
            " |      ...                      missing_fraction=0,\n",
            " |      ...                      rows=744, cols=1)\n",
            " |      >>> w.set_names([\"weight\"])\n",
            " |      >>> train = train.cbind(w)\n",
            " |      >>> ecology_gbm = H2OGradientBoostingEstimator(ntrees=10,\n",
            " |      ...                                            max_depth=5,\n",
            " |      ...                                            min_rows=10,\n",
            " |      ...                                            learn_rate=0.1,\n",
            " |      ...                                            distribution=\"multinomial\",\n",
            " |      ...                                            weights_column=\"weight\",\n",
            " |      ...                                            calibrate_model=True,\n",
            " |      ...                                            calibration_frame=calib)\n",
            " |      >>> ecology_gbm.train(x=predictors,\n",
            " |      ...                   y=\"Angaus\",\n",
            " |      ...                   training_frame=train)\n",
            " |      >>> ecology_gbm.auc()\n",
            " |  \n",
            " |  calibration_frame\n",
            " |      Calibration frame for Platt Scaling\n",
            " |      \n",
            " |      Type: ``H2OFrame``.\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> ecology = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/ecology_model.csv\")\n",
            " |      >>> ecology['Angaus'] = ecology['Angaus'].asfactor()\n",
            " |      >>> response = 'Angaus'\n",
            " |      >>> predictors = ecology.columns[3:13]\n",
            " |      >>> train, calib = ecology.split_frame(seed=12354)\n",
            " |      >>> w = h2o.create_frame(binary_fraction=1,\n",
            " |      ...                      binary_ones_fraction=0.5,\n",
            " |      ...                      missing_fraction=0,\n",
            " |      ...                      rows=744,cols=1)\n",
            " |      >>> w.set_names([\"weight\"])\n",
            " |      >>> train = train.cbind(w)\n",
            " |      >>> ecology_gbm = H2OGradientBoostingEstimator(ntrees=10,\n",
            " |      ...                                            max_depth=5,\n",
            " |      ...                                            min_rows=10,\n",
            " |      ...                                            learn_rate=0.1,\n",
            " |      ...                                            distribution=\"multinomial\",\n",
            " |      ...                                            calibrate_model=True,\n",
            " |      ...                                            calibration_frame=calib)\n",
            " |      >>> ecology_gbm.train(x=predictors,\n",
            " |      ...                   y=\"Angaus\",\n",
            " |      ...                   training_frame=train,\n",
            " |      ...                   weights_column=\"weight\")\n",
            " |      >>> ecology_gbm.auc()\n",
            " |  \n",
            " |  categorical_encoding\n",
            " |      Encoding scheme for categorical features\n",
            " |      \n",
            " |      One of: ``\"auto\"``, ``\"enum\"``, ``\"one_hot_internal\"``, ``\"one_hot_explicit\"``, ``\"binary\"``, ``\"eigen\"``,\n",
            " |      ``\"label_encoder\"``, ``\"sort_by_response\"``, ``\"enum_limited\"``  (default: ``\"auto\"``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
            " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
            " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
            " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
            " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
            " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
            " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
            " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
            " |      >>> response = \"IsDepDelayed\"\n",
            " |      >>> train, valid = airlines.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> airlines_gbm = H2OGradientBoostingEstimator(categorical_encoding=\"labelencoder\",\n",
            " |      ...                                             seed=1234)\n",
            " |      >>> airlines_gbm.train(x=predictors,\n",
            " |      ...                    y=response,\n",
            " |      ...                    training_frame=train,\n",
            " |      ...                    validation_frame=valid)\n",
            " |      >>> airlines_gbm.auc(valid=True)\n",
            " |  \n",
            " |  check_constant_response\n",
            " |      Check if response column is constant. If enabled, then an exception is thrown if the response column is a\n",
            " |      constant value.If disabled, then model will train regardless of the response column being a constant value or\n",
            " |      not.\n",
            " |      \n",
            " |      Type: ``bool``  (default: ``True``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> train = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/iris/iris_train.csv\")\n",
            " |      >>> train[\"constantCol\"] = 1\n",
            " |      >>> my_gbm = H2OGradientBoostingEstimator(check_constant_response=False)\n",
            " |      >>> my_gbm.train(x=list(range(1,5)),\n",
            " |      ...              y=\"constantCol\",\n",
            " |      ...              training_frame=train)\n",
            " |  \n",
            " |  checkpoint\n",
            " |      Model checkpoint to resume training with.\n",
            " |      \n",
            " |      Type: ``str``.\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
            " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
            " |      >>> response = \"economy_20mpg\"\n",
            " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(ntrees=1,\n",
            " |      ...                                         seed=1234)\n",
            " |      >>> cars_gbm.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=train,\n",
            " |      ...                validation_frame=valid)\n",
            " |      >>> print(cars_gbm.auc(valid=True))\n",
            " |      >>> print(\"Number of trees built for cars_gbm model:\", cars_gbm.ntrees)\n",
            " |      >>> cars_gbm_continued = H2OGradientBoostingEstimator(checkpoint=cars_gbm.model_id,\n",
            " |      ...                                                   ntrees=50,\n",
            " |      ...                                                   seed=1234)\n",
            " |      >>> cars_gbm_continued.train(x=predictors,\n",
            " |      ...                          y=response,\n",
            " |      ...                          training_frame=train,\n",
            " |      ...                          validation_frame=valid)\n",
            " |      >>> cars_gbm_continued.auc(valid=True)\n",
            " |      >>> print(\"Number of trees built for cars_gbm model:\",cars_gbm_continued.ntrees)\n",
            " |  \n",
            " |  class_sampling_factors\n",
            " |      Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will\n",
            " |      be automatically computed to obtain class balance during training. Requires balance_classes.\n",
            " |      \n",
            " |      Type: ``List[float]``.\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> covtype = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/covtype/covtype.20k.data\")\n",
            " |      >>> covtype[54] = covtype[54].asfactor()\n",
            " |      >>> predictors = covtype.columns[0:54]\n",
            " |      >>> response = 'C55'\n",
            " |      >>> train, valid = covtype.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> sample_factors = [1., 0.5, 1., 1., 1., 1., 1.]\n",
            " |      >>> cov_gbm = H2OGradientBoostingEstimator(balance_classes=True,\n",
            " |      ...                                        class_sampling_factors=sample_factors,\n",
            " |      ...                                        seed=1234)\n",
            " |      >>> cov_gbm.train(x=predictors,\n",
            " |      ...               y=response,\n",
            " |      ...               training_frame=train,\n",
            " |      ...               validation_frame=valid)\n",
            " |      >>> cov_gbm.logloss(valid=True)\n",
            " |  \n",
            " |  col_sample_rate\n",
            " |      Column sample rate (from 0.0 to 1.0)\n",
            " |      \n",
            " |      Type: ``float``  (default: ``1``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
            " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
            " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
            " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
            " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
            " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
            " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
            " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
            " |      >>> response = \"IsDepDelayed\"\n",
            " |      >>> train, valid = airlines.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> airlines_gbm = H2OGradientBoostingEstimator(col_sample_rate=.7,\n",
            " |      ...                                             seed=1234)\n",
            " |      >>> airlines_gbm.train(x=predictors,\n",
            " |      ...                    y=response,\n",
            " |      ...                    training_frame=train,\n",
            " |      ...                    validation_frame=valid)\n",
            " |      >>> airlines_gbm.auc(valid=True)\n",
            " |  \n",
            " |  col_sample_rate_change_per_level\n",
            " |      Relative change of the column sampling rate for every level (must be > 0.0 and <= 2.0)\n",
            " |      \n",
            " |      Type: ``float``  (default: ``1``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
            " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
            " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
            " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
            " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
            " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
            " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
            " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
            " |      >>> response = \"IsDepDelayed\"\n",
            " |      >>> train, valid = airlines.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> airlines_gbm = H2OGradientBoostingEstimator(col_sample_rate_change_per_level=.9,\n",
            " |      ...                                             seed=1234)\n",
            " |      >>> airlines_gbm.train(x=predictors,\n",
            " |      ...                    y=response,\n",
            " |      ...                    training_frame=train,\n",
            " |      ...                    validation_frame=valid)\n",
            " |      >>> airlines_gbm.auc(valid=True)\n",
            " |  \n",
            " |  col_sample_rate_per_tree\n",
            " |      Column sample rate per tree (from 0.0 to 1.0)\n",
            " |      \n",
            " |      Type: ``float``  (default: ``1``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
            " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
            " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
            " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
            " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
            " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
            " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
            " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
            " |      >>> response = \"IsDepDelayed\"\n",
            " |      >>> train, valid = airlines.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> airlines_gbm = H2OGradientBoostingEstimator(col_sample_rate_per_tree=.7,\n",
            " |      ...                                             seed=1234)\n",
            " |      >>> airlines_gbm.train(x=predictors,\n",
            " |      ...                    y=response,\n",
            " |      ...                    training_frame=train,\n",
            " |      ...                    validation_frame=valid)\n",
            " |      >>> airlines_gbm.auc(valid=True)\n",
            " |  \n",
            " |  custom_distribution_func\n",
            " |      Reference to custom distribution, format: `language:keyName=funcName`\n",
            " |      \n",
            " |      Type: ``str``.\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
            " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
            " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
            " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
            " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
            " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
            " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
            " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
            " |      >>> response = \"IsDepDelayed\"\n",
            " |      >>> train, valid = airlines.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> airlines_gbm = H2OGradientBoostingEstimator(ntrees=3,\n",
            " |      ...                                             max_depth=5,\n",
            " |      ...                                             distribution=\"bernoulli\",\n",
            " |      ...                                             seed=1234)\n",
            " |      >>> airlines_gbm.train(x=predictors,\n",
            " |      ...                    y=response,\n",
            " |      ...                    training_frame=train,\n",
            " |      ...                    validation_frame valid)\n",
            " |      >>> from h2o.utils.distributions import CustomDistributionBernoulli\n",
            " |      >>> custom_distribution_bernoulli = h2o.upload_custom_distribution(CustomDistributionBernoulli,\n",
            " |      ...                                                                func_name=\"custom_bernoulli\",\n",
            " |      ...                                                                func_file=\"custom_bernoulli.py\")\n",
            " |      >>> airlines_gbm_custom = H2OGradientBoostingEstimator(ntrees=3,\n",
            " |      ...                                                    max_depth=5,\n",
            " |      ...                                                    distribution=\"custom\",\n",
            " |      ...                                                    custom_distribution_func=custom_distribution_bernoulli,\n",
            " |      ...                                                    seed=1235)\n",
            " |      >>> airlines_gbm_custom.train(x=predictors,\n",
            " |      ...                           y=response,\n",
            " |      ...                           training_frame=train,\n",
            " |      ...                           validation_frame=valid)\n",
            " |      >>> airlines_gbm.auc()\n",
            " |  \n",
            " |  custom_metric_func\n",
            " |      Reference to custom evaluation function, format: `language:keyName=funcName`\n",
            " |      \n",
            " |      Type: ``str``.\n",
            " |  \n",
            " |  distribution\n",
            " |      Distribution function\n",
            " |      \n",
            " |      One of: ``\"auto\"``, ``\"bernoulli\"``, ``\"quasibinomial\"``, ``\"multinomial\"``, ``\"gaussian\"``, ``\"poisson\"``,\n",
            " |      ``\"gamma\"``, ``\"tweedie\"``, ``\"laplace\"``, ``\"quantile\"``, ``\"huber\"``, ``\"custom\"``  (default: ``\"auto\"``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> response = \"cylinders\"\n",
            " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(distribution=\"poisson\",\n",
            " |      ...                                         seed=1234)\n",
            " |      >>> cars_gbm.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=train,\n",
            " |      ...                validation_frame=valid)\n",
            " |      >>> cars_gbm.mse(valid=True)\n",
            " |  \n",
            " |  export_checkpoints_dir\n",
            " |      Automatically export generated models to this directory.\n",
            " |      \n",
            " |      Type: ``str``.\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> airlines = h2o.import_file(\"http://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\", destination_frame=\"air.hex\")\n",
            " |      >>> predictors = [\"DayofMonth\", \"DayOfWeek\"]\n",
            " |      >>> response = \"IsDepDelayed\"\n",
            " |      >>> hyper_parameters = {'ntrees': [5,10]}\n",
            " |      >>> search_crit = {'strategy': \"RandomDiscrete\",\n",
            " |      ...                'max_models': 5,\n",
            " |      ...                'seed': 1234,\n",
            " |      ...                'stopping_rounds': 3,\n",
            " |      ...                'stopping_metric': \"AUTO\",\n",
            " |      ...                'stopping_tolerance': 1e-2}\n",
            " |      >>> checkpoints_dir = tempfile.mkdtemp()\n",
            " |      >>> air_grid = H2OGridSearch(H2OGradientBoostingEstimator,\n",
            " |      ...                          hyper_params=hyper_parameters,\n",
            " |      ...                          search_criteria=search_crit)\n",
            " |      >>> air_grid.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=airlines,\n",
            " |      ...                distribution=\"bernoulli\",\n",
            " |      ...                learn_rate=0.1,\n",
            " |      ...                max_depth=3,\n",
            " |      ...                export_checkpoints_dir=checkpoints_dir)\n",
            " |      >>> len(listdir(checkpoints_dir))\n",
            " |  \n",
            " |  fold_assignment\n",
            " |      Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will stratify\n",
            " |      the folds based on the response variable, for classification problems.\n",
            " |      \n",
            " |      One of: ``\"auto\"``, ``\"random\"``, ``\"modulo\"``, ``\"stratified\"``  (default: ``\"auto\"``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
            " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
            " |      >>> response = \"economy_20mpg\"\n",
            " |      >>> assignment_type = \"Random\"\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(fold_assignment=assignment_type,\n",
            " |      ...                                         nfolds=5,\n",
            " |      ...                                         seed=1234)\n",
            " |      >>> cars_gbm.train(x=predictors, y=response, training_frame=cars)\n",
            " |      >>> cars_gbm.auc(xval=True)\n",
            " |  \n",
            " |  fold_column\n",
            " |      Column with cross-validation fold index assignment per observation.\n",
            " |      \n",
            " |      Type: ``str``.\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
            " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
            " |      >>> response = \"economy_20mpg\"\n",
            " |      >>> fold_numbers = cars.kfold_column(n_folds=5,\n",
            " |      ...                                  seed=1234)\n",
            " |      >>> fold_numbers.set_names([\"fold_numbers\"])\n",
            " |      >>> cars = cars.cbind(fold_numbers)\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(seed=1234)\n",
            " |      >>> cars_gbm.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=cars,\n",
            " |      ...                fold_column=\"fold_numbers\")\n",
            " |      >>> cars_gbm.auc(xval=True)\n",
            " |  \n",
            " |  histogram_type\n",
            " |      What type of histogram to use for finding optimal split points\n",
            " |      \n",
            " |      One of: ``\"auto\"``, ``\"uniform_adaptive\"``, ``\"random\"``, ``\"quantiles_global\"``, ``\"round_robin\"``  (default:\n",
            " |      ``\"auto\"``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
            " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
            " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
            " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
            " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
            " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
            " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
            " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
            " |      >>> response = \"IsDepDelayed\"\n",
            " |      >>> train, valid = airlines.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> airlines_gbm = H2OGradientBoostingEstimator(histogram_type=\"UniformAdaptive\",\n",
            " |      ...                                             seed=1234)\n",
            " |      >>> airlines_gbm.train(x=predictors,\n",
            " |      ...                    y=response,\n",
            " |      ...                    training_frame=train,\n",
            " |      ...                    validation_frame=valid)\n",
            " |      >>> airlines_gbm.auc(valid=True)\n",
            " |  \n",
            " |  huber_alpha\n",
            " |      Desired quantile for Huber/M-regression (threshold between quadratic and linear loss, must be between 0 and 1).\n",
            " |      \n",
            " |      Type: ``float``  (default: ``0.9``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> insurance = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/glm_test/insurance.csv\")\n",
            " |      >>> predictors = insurance.columns[0:4]\n",
            " |      >>> response = 'Claims'\n",
            " |      >>> insurance['Group'] = insurance['Group'].asfactor()\n",
            " |      >>> insurance['Age'] = insurance['Age'].asfactor()\n",
            " |      >>> train, valid = insurance.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> insurance_gbm = H2OGradientBoostingEstimator(distribution=\"huber\",\n",
            " |      ...                                              huber_alpha=0.9,\n",
            " |      ...                                              seed=1234)\n",
            " |      >>> insurance_gbm.train(x=predictors,\n",
            " |      ...                     y=response,\n",
            " |      ...                     training_frame=train,\n",
            " |      ...                     validation_frame=valid)\n",
            " |      >>> insurance_gbm.mse(valid=True)\n",
            " |  \n",
            " |  ignore_const_cols\n",
            " |      Ignore constant columns.\n",
            " |      \n",
            " |      Type: ``bool``  (default: ``True``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
            " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
            " |      >>> response = \"economy_20mpg\"\n",
            " |      >>> cars[\"const_1\"] = 6\n",
            " |      >>> cars[\"const_2\"] = 7\n",
            " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(seed=1234,\n",
            " |      ...                                         ignore_const_cols=True)\n",
            " |      >>> cars_gbm.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=train,\n",
            " |      ...                validation_frame=valid)\n",
            " |      >>> cars_gbm.auc(valid=True)\n",
            " |  \n",
            " |  ignored_columns\n",
            " |      Names of columns to ignore for training.\n",
            " |      \n",
            " |      Type: ``List[str]``.\n",
            " |  \n",
            " |  keep_cross_validation_fold_assignment\n",
            " |      Whether to keep the cross-validation fold assignment.\n",
            " |      \n",
            " |      Type: ``bool``  (default: ``False``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
            " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
            " |      >>> response = \"economy_20mpg\"\n",
            " |      >>> folds = 5\n",
            " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(keep_cross_validation_fold_assignment=True,\n",
            " |      ...                                         nfolds=5,\n",
            " |      ...                                         seed=1234)\n",
            " |      >>> cars_gbm.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=train,\n",
            " |      ...                validation_frame=valid)\n",
            " |      >>> cars_gbm.auc()\n",
            " |  \n",
            " |  keep_cross_validation_models\n",
            " |      Whether to keep the cross-validation models.\n",
            " |      \n",
            " |      Type: ``bool``  (default: ``True``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
            " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
            " |      >>> response = \"economy_20mpg\"\n",
            " |      >>> folds = 5\n",
            " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(keep_cross_validation_models=True,\n",
            " |      ...                                         nfolds=5,\n",
            " |      ...                                         seed=1234)\n",
            " |      >>> cars_gbm.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=train,\n",
            " |      ...                validation_frame=valid)\n",
            " |      >>> cars_gbm.auc()\n",
            " |  \n",
            " |  keep_cross_validation_predictions\n",
            " |      Whether to keep the predictions of the cross-validation models.\n",
            " |      \n",
            " |      Type: ``bool``  (default: ``False``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
            " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
            " |      >>> response = \"economy_20mpg\"\n",
            " |      >>> folds = 5\n",
            " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(keep_cross_validation_predictions=True,\n",
            " |      ...                                         nfolds=5,\n",
            " |      ...                                         seed=1234)\n",
            " |      >>> cars_gbm.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=train,\n",
            " |      ...                validation_frame=valid)\n",
            " |      >>> cars_gbm.auc()\n",
            " |  \n",
            " |  learn_rate\n",
            " |      Learning rate (from 0.0 to 1.0)\n",
            " |      \n",
            " |      Type: ``float``  (default: ``0.1``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> titanic = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
            " |      >>> titanic['survived'] = titanic['survived'].asfactor()\n",
            " |      >>> predictors = titanic.columns\n",
            " |      >>> del predictors[1:3]\n",
            " |      >>> response = 'survived'\n",
            " |      >>> train, valid = titanic.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> titanic_gbm = H2OGradientBoostingEstimator(ntrees=10000,\n",
            " |      ...                                            learn_rate=0.01,\n",
            " |      ...                                            stopping_rounds=5,\n",
            " |      ...                                            stopping_metric=\"AUC\",\n",
            " |      ...                                            stopping_tolerance=1e-4,\n",
            " |      ...                                            seed=1234)\n",
            " |      >>> titanic_gbm.train(x=predictors,\n",
            " |      ...                   y=response,\n",
            " |      ...                   training_frame=train,\n",
            " |      ...                   validation_frame=valid)\n",
            " |      >>> titanic_gbm.auc(valid=True)\n",
            " |  \n",
            " |  learn_rate_annealing\n",
            " |      Scale the learning rate by this factor after each tree (e.g., 0.99 or 0.999)\n",
            " |      \n",
            " |      Type: ``float``  (default: ``1``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> titanic = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
            " |      >>> titanic['survived'] = titanic['survived'].asfactor()\n",
            " |      >>> predictors = titanic.columns\n",
            " |      >>> del predictors[1:3]\n",
            " |      >>> response = 'survived'\n",
            " |      >>> train, valid = titanic.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> titanic_gbm = H2OGradientBoostingEstimator(ntrees=10000,\n",
            " |      ...                                            learn_rate=0.05,\n",
            " |      ...                                            learn_rate_annealing=.9,\n",
            " |      ...                                            stopping_rounds=5,\n",
            " |      ...                                            stopping_metric=\"AUC\",\n",
            " |      ...                                            stopping_tolerance=1e-4,\n",
            " |      ...                                            seed=1234)\n",
            " |      >>> titanic_gbm.train(x=predictors,\n",
            " |      ...                   y=response,\n",
            " |      ...                   training_frame=train,\n",
            " |      ...                   validation_frame=valid)\n",
            " |      >>> titanic_gbm.auc(valid=True)\n",
            " |  \n",
            " |  max_abs_leafnode_pred\n",
            " |      Maximum absolute value of a leaf node prediction\n",
            " |      \n",
            " |      Type: ``float``  (default: ``1.797693135e+308``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> covtype = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/covtype/covtype.20k.data\")\n",
            " |      >>> covtype[54] = covtype[54].asfactor()\n",
            " |      >>> predictors = covtype.columns[0:54]\n",
            " |      >>> response = 'C55'\n",
            " |      >>> train, valid = covtype.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> cov_gbm = H2OGradientBoostingEstimator(max_abs_leafnode_pred=2,\n",
            " |      ...                                        seed=1234)\n",
            " |      >>> cov_gbm.train(x=predictors,\n",
            " |      ...               y=response,\n",
            " |      ...               training_frame=train,\n",
            " |      ...               validation_frame=valid)\n",
            " |      >>> cov_gbm.logloss(valid=True)\n",
            " |  \n",
            " |  max_after_balance_size\n",
            " |      Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires\n",
            " |      balance_classes.\n",
            " |      \n",
            " |      Type: ``float``  (default: ``5``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> covtype = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/covtype/covtype.20k.data\")\n",
            " |      >>> covtype[54] = covtype[54].asfactor()\n",
            " |      >>> predictors = covtype.columns[0:54]\n",
            " |      >>> response = 'C55'\n",
            " |      >>> train, valid = covtype.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> max = .85\n",
            " |      >>> cov_gbm = H2OGradientBoostingEstimator(balance_classes=True,\n",
            " |      ...                                        max_after_balance_size=max,\n",
            " |      ...                                        seed=1234)\n",
            " |      >>> cov_gbm.train(x=predictors,\n",
            " |      ...               y=response,\n",
            " |      ...               training_frame=train,\n",
            " |      ...               validation_frame=valid)\n",
            " |      >>> cov_gbm.logloss(valid=True)\n",
            " |  \n",
            " |  max_confusion_matrix_size\n",
            " |      [Deprecated] Maximum size (# classes) for confusion matrices to be printed in the Logs\n",
            " |      \n",
            " |      Type: ``int``  (default: ``20``).\n",
            " |  \n",
            " |  max_depth\n",
            " |      Maximum tree depth.\n",
            " |      \n",
            " |      Type: ``int``  (default: ``5``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
            " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
            " |      >>> response = \"economy_20mpg\"\n",
            " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(ntrees=100,\n",
            " |      ...                                         max_depth=2,\n",
            " |      ...                                         seed=1234)\n",
            " |      >>> cars_gbm.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=train,\n",
            " |      ...                validation_frame=valid)\n",
            " |      >>> cars_gbm.auc(valid=True)\n",
            " |  \n",
            " |  max_hit_ratio_k\n",
            " |      Max. number (top K) of predictions to use for hit ratio computation (for multi-class only, 0 to disable)\n",
            " |      \n",
            " |      Type: ``int``  (default: ``0``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> covtype = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/covtype/covtype.20k.data\")\n",
            " |      >>> covtype[54] = covtype[54].asfactor()\n",
            " |      >>> predictors = covtype.columns[0:54]\n",
            " |      >>> response = 'C55'\n",
            " |      >>> train, valid = covtype.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> cov_gbm = H2OGradientBoostingEstimator(max_hit_ratio_k=3,\n",
            " |      ...                                        seed=1234)\n",
            " |      >>> cov_gbm.train(x=predictors,\n",
            " |      ...               y=response,\n",
            " |      ...               training_frame=train,\n",
            " |      ...               validation_frame=valid)\n",
            " |      >>> cov_gbm.logloss(valid=True)\n",
            " |  \n",
            " |  max_runtime_secs\n",
            " |      Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
            " |      \n",
            " |      Type: ``float``  (default: ``0``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
            " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
            " |      >>> response = \"economy_20mpg\"\n",
            " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(max_runtime_secs=10,\n",
            " |      ...                                         ntrees=10000,\n",
            " |      ...                                         max_depth=10,\n",
            " |      ...                                         seed=1234)\n",
            " |      >>> cars_gbm.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=train,\n",
            " |      ...                validation_frame=valid)\n",
            " |      >>> cars_gbm.auc(valid=True)\n",
            " |  \n",
            " |  min_rows\n",
            " |      Fewest allowed (weighted) observations in a leaf.\n",
            " |      \n",
            " |      Type: ``float``  (default: ``10``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
            " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
            " |      >>> response = \"economy_20mpg\"\n",
            " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(min_rows=16,\n",
            " |      ...                                         seed=1234)\n",
            " |      >>> cars_gbm.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=train,\n",
            " |      ...                validation_frame=valid)\n",
            " |      >>> cars_gbm.auc(valid=True)\n",
            " |  \n",
            " |  min_split_improvement\n",
            " |      Minimum relative improvement in squared error reduction for a split to happen\n",
            " |      \n",
            " |      Type: ``float``  (default: ``1e-05``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
            " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
            " |      >>> response = \"economy_20mpg\"\n",
            " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(min_split_improvement=1e-3,\n",
            " |      ...                                         seed=1234)\n",
            " |      >>> cars_gbm.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=train,\n",
            " |      ...                validation_frame=valid)\n",
            " |      >>> cars_gbm.auc(valid=True)\n",
            " |  \n",
            " |  monotone_constraints\n",
            " |      A mapping representing monotonic constraints. Use +1 to enforce an increasing constraint and -1 to specify a\n",
            " |      decreasing constraint.\n",
            " |      \n",
            " |      Type: ``dict``.\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> prostate_hex = h2o.import_file(\"http://s3.amazonaws.com/h2o-public-test-data/smalldata/prostate/prostate.csv.zip\")\n",
            " |      >>> prostate_hex[\"CAPSULE\"] = prostate_hex[\"CAPSULE\"].asfactor()\n",
            " |      >>> response = \"CAPSULE\"\n",
            " |      >>> seed = 42\n",
            " |      >>> monotone_constraints = {\"AGE\":1}\n",
            " |      >>> gbm_model = H2OGradientBoostingEstimator(seed=seed,\n",
            " |      ...                                          monotone_constraints=monotone_constraints)\n",
            " |      >>> gbm_model.train(y=response,\n",
            " |      ...                 ignored_columns=[\"ID\"],\n",
            " |      ...                 training_frame=prostate_hex)\n",
            " |      >>> gbm_model.scoring_history()\n",
            " |  \n",
            " |  nbins\n",
            " |      For numerical columns (real/int), build a histogram of (at least) this many bins, then split at the best point\n",
            " |      \n",
            " |      Type: ``int``  (default: ``20``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> eeg = h2o.import_file(\"https://h2o-public-test-data.s3.amazonaws.com/smalldata/eeg/eeg_eyestate.csv\")\n",
            " |      >>> eeg['eyeDetection'] = eeg['eyeDetection'].asfactor()\n",
            " |      >>> predictors = eeg.columns[:-1]\n",
            " |      >>> response = 'eyeDetection'\n",
            " |      >>> train, valid = eeg.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> bin_num = [16, 32, 64, 128, 256, 512]\n",
            " |      >>> label = [\"16\", \"32\", \"64\", \"128\", \"256\", \"512\"]\n",
            " |      >>> for key, num in enumerate(bin_num):\n",
            " |      ...     eeg_gbm = H2OGradientBoostingEstimator(nbins=num, seed=1234)\n",
            " |      ...     eeg_gbm.train(x=predictors,\n",
            " |      ...                   y=response,\n",
            " |      ...                   training_frame=train,\n",
            " |      ...                   validation_frame=valid)\n",
            " |      ...     print(label[key], 'training score', eeg_gbm.auc(train=True)) \n",
            " |      ...     print(label[key], 'validation score', eeg_gbm.auc(valid=True))\n",
            " |  \n",
            " |  nbins_cats\n",
            " |      For categorical columns (factors), build a histogram of this many bins, then split at the best point. Higher\n",
            " |      values can lead to more overfitting.\n",
            " |      \n",
            " |      Type: ``int``  (default: ``1024``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
            " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
            " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
            " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
            " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
            " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
            " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
            " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
            " |      >>> response = \"IsDepDelayed\"\n",
            " |      >>> train, valid = airlines.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> bin_num = [8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]\n",
            " |      >>> label = [\"8\", \"16\", \"32\", \"64\", \"128\", \"256\", \"512\", \"1024\", \"2048\", \"4096\"]\n",
            " |      >>> for key, num in enumerate(bin_num):\n",
            " |      ...     airlines_gbm = H2OGradientBoostingEstimator(nbins_cats=num, seed=1234)\n",
            " |      ...     airlines_gbm.train(x=predictors,\n",
            " |      ...                        y=response,\n",
            " |      ...                        training_frame=train,\n",
            " |      ...                        validation_frame=valid)\n",
            " |      ...     print(label[key], 'training score', airlines_gbm.auc(train=True))\n",
            " |      ...     print(label[key], 'validation score', airlines_gbm.auc(valid=True))\n",
            " |  \n",
            " |  nbins_top_level\n",
            " |      For numerical columns (real/int), build a histogram of (at most) this many bins at the root level, then decrease\n",
            " |      by factor of two per level\n",
            " |      \n",
            " |      Type: ``int``  (default: ``1024``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> eeg = h2o.import_file(\"https://h2o-public-test-data.s3.amazonaws.com/smalldata/eeg/eeg_eyestate.csv\")\n",
            " |      >>> eeg['eyeDetection'] = eeg['eyeDetection'].asfactor()\n",
            " |      >>> predictors = eeg.columns[:-1]\n",
            " |      >>> response = 'eyeDetection'\n",
            " |      >>> train, valid = eeg.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> bin_num = [32, 64, 128, 256, 512, 1024, 2048, 4096]\n",
            " |      >>> label = [\"32\", \"64\", \"128\", \"256\", \"512\", \"1024\", \"2048\", \"4096\"]\n",
            " |      >>> for key, num in enumerate(bin_num):\n",
            " |      ...     eeg_gbm = H2OGradientBoostingEstimator(nbins_top_level=num, seed=1234)\n",
            " |      ...     eeg_gbm.train(x=predictors,\n",
            " |      ...                   y=response,\n",
            " |      ...                   training_frame=train,\n",
            " |      ...                   validation_frame=valid)\n",
            " |      ...     print(label[key], 'training score', eeg_gbm.auc(train=True)) \n",
            " |      ...     print(label[key], 'validation score', eeg_gbm.auc(valid=True))\n",
            " |  \n",
            " |  nfolds\n",
            " |      Number of folds for K-fold cross-validation (0 to disable or >= 2).\n",
            " |      \n",
            " |      Type: ``int``  (default: ``0``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
            " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
            " |      >>> response = \"economy_20mpg\"\n",
            " |      >>> folds = 5\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(nfolds=folds,\n",
            " |      ...                                         seed=1234\n",
            " |      >>> cars_gbm.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=cars)\n",
            " |      >>> cars_gbm.auc()\n",
            " |  \n",
            " |  ntrees\n",
            " |      Number of trees.\n",
            " |      \n",
            " |      Type: ``int``  (default: ``50``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> titanic = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
            " |      >>> titanic['survived'] = titanic['survived'].asfactor()\n",
            " |      >>> predictors = titanic.columns\n",
            " |      >>> del predictors[1:3]\n",
            " |      >>> response = 'survived'\n",
            " |      >>> train, valid = titanic.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> tree_num = [20, 50, 80, 110, 140, 170, 200]\n",
            " |      >>> label = [\"20\", \"50\", \"80\", \"110\", \"140\", \"170\", \"200\"]\n",
            " |      >>> for key, num in enumerate(tree_num):\n",
            " |      ...     titanic_gbm = H2OGradientBoostingEstimator(ntrees=num,\n",
            " |      ...                                                seed=1234)\n",
            " |      ...     titanic_gbm.train(x=predictors,\n",
            " |      ...                       y=response,\n",
            " |      ...                       training_frame=train,\n",
            " |      ...                       validation_frame=valid)\n",
            " |      ...     print(label[key], 'training score', titanic_gbm.auc(train=True))\n",
            " |      ...     print(label[key], 'validation score', titanic_gbm.auc(valid=True))\n",
            " |  \n",
            " |  offset_column\n",
            " |      Offset column. This will be added to the combination of columns before applying the link function.\n",
            " |      \n",
            " |      Type: ``str``.\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> boston = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/BostonHousing.csv\")\n",
            " |      >>> predictors = boston.columns[:-1]\n",
            " |      >>> response = \"medv\"\n",
            " |      >>> boston['chas'] = boston['chas'].asfactor()\n",
            " |      >>> boston[\"offset\"] = boston[\"medv\"].log()\n",
            " |      >>> train, valid = boston.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> boston_gbm = H2OGradientBoostingEstimator(offset_column=\"offset\",\n",
            " |      ...                                           seed=1234)\n",
            " |      >>> boston_gbm.train(x=predictors,\n",
            " |      ...                  y=response,\n",
            " |      ...                  training_frame=train,\n",
            " |      ...                  validation_frame=valid)\n",
            " |      >>> boston_gbm.mse(valid=True)\n",
            " |  \n",
            " |  pred_noise_bandwidth\n",
            " |      Bandwidth (sigma) of Gaussian multiplicative noise ~N(1,sigma) for tree node predictions\n",
            " |      \n",
            " |      Type: ``float``  (default: ``0``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> titanic = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\")\n",
            " |      >>> titanic['survived'] = titanic['survived'].asfactor()\n",
            " |      >>> predictors = titanic.columns\n",
            " |      >>> del predictors[1:3]\n",
            " |      >>> response = 'survived'\n",
            " |      >>> train, valid = titanic.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> titanic_gbm = H2OGradientBoostingEstimator(pred_noise_bandwidth=0.1,\n",
            " |      ...                                            seed=1234)\n",
            " |      >>> titanic_gbm.train(x=predictors,\n",
            " |      ...                   y=response,\n",
            " |      ...                   training_frame=train,\n",
            " |      ...                   validation_frame=valid)\n",
            " |      >>> titanic_gbm.auc(valid = True)\n",
            " |  \n",
            " |  quantile_alpha\n",
            " |      Desired quantile for Quantile regression, must be between 0 and 1.\n",
            " |      \n",
            " |      Type: ``float``  (default: ``0.5``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> boston = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/BostonHousing.csv\")\n",
            " |      >>> predictors = boston.columns[:-1]\n",
            " |      >>> response = \"medv\"\n",
            " |      >>> boston['chas'] = boston['chas'].asfactor()\n",
            " |      >>> train, valid = boston.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> boston_gbm = H2OGradientBoostingEstimator(distribution=\"quantile\",\n",
            " |      ...                                           quantile_alpha=.8,\n",
            " |      ...                                           seed=1234)\n",
            " |      >>> boston_gbm.train(x=predictors,\n",
            " |      ...                  y=response,\n",
            " |      ...                  training_frame=train,\n",
            " |      ...                  validation_frame=valid)\n",
            " |      >>> boston_gbm.mse(valid=True)\n",
            " |  \n",
            " |  r2_stopping\n",
            " |      r2_stopping is no longer supported and will be ignored if set - please use stopping_rounds, stopping_metric and\n",
            " |      stopping_tolerance instead. Previous version of H2O would stop making trees when the R^2 metric equals or\n",
            " |      exceeds this\n",
            " |      \n",
            " |      Type: ``float``  (default: ``1.797693135e+308``).\n",
            " |  \n",
            " |  response_column\n",
            " |      Response variable column.\n",
            " |      \n",
            " |      Type: ``str``.\n",
            " |  \n",
            " |  sample_rate\n",
            " |      Row sample rate per tree (from 0.0 to 1.0)\n",
            " |      \n",
            " |      Type: ``float``  (default: ``1``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
            " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()                             >>> airlines[\"Year\"]= airlines[\"Year\"].asfactor()\n",
            " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
            " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
            " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
            " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
            " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
            " |      >>> response = \"IsDepDelayed\"\n",
            " |      >>> train, valid = airlines.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> airlines_gbm = H2OGradientBoostingEstimator(sample_rate=.7,\n",
            " |      ...                                             seed=1234)\n",
            " |      >>> airlines_gbm.train(x=predictors,\n",
            " |      ...                    y=response,\n",
            " |      ...                    training_frame=train,\n",
            " |      ...                    validation_frame=valid)\n",
            " |      >>> airlines_gbm.auc(valid=True)\n",
            " |  \n",
            " |  sample_rate_per_class\n",
            " |      A list of row sample rates per class (relative fraction for each class, from 0.0 to 1.0), for each tree\n",
            " |      \n",
            " |      Type: ``List[float]``.\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> covtype = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/covtype/covtype.20k.data\")\n",
            " |      >>> covtype[54] = covtype[54].asfactor()\n",
            " |      >>> predictors = covtype.columns[0:54]\n",
            " |      >>> response = 'C55'\n",
            " |      >>> train, valid = covtype.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> rate_per_class_list = [1, .4, 1, 1, 1, 1, 1]\n",
            " |      >>> cov_gbm = H2OGradientBoostingEstimator(sample_rate_per_class=rate_per_class_list,\n",
            " |      ...                                        seed=1234)\n",
            " |      >>> cov_gbm.train(x=predictors,\n",
            " |      ...               y=response,\n",
            " |      ...               training_frame=train,\n",
            " |      ...               validation_frame=valid)\n",
            " |      >>> cov_gbm.logloss(valid=True)\n",
            " |  \n",
            " |  score_each_iteration\n",
            " |      Whether to score during each iteration of model training.\n",
            " |      \n",
            " |      Type: ``bool``  (default: ``False``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
            " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
            " |      >>> response = \"economy_20mpg\"\n",
            " |      >>> train, valid = cars.split_frame(ratios=[.8],\n",
            " |      ...                                 seed=1234)\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(score_each_iteration=True,\n",
            " |      ...                                         ntrees=55,\n",
            " |      ...                                         seed=1234)\n",
            " |      >>> cars_gbm.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=train,\n",
            " |      ...                validation_frame=valid)\n",
            " |      >>> cars_gbm.scoring_history()\n",
            " |  \n",
            " |  score_tree_interval\n",
            " |      Score the model after every so many trees. Disabled if set to 0.\n",
            " |      \n",
            " |      Type: ``int``  (default: ``0``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
            " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
            " |      >>> response = \"economy_20mpg\"\n",
            " |      >>> train, valid = cars.split_frame(ratios=[.8],\n",
            " |      ...                                 seed=1234)\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(score_tree_interval=True,\n",
            " |      ...                                         ntrees=55,\n",
            " |      ...                                         seed=1234)\n",
            " |      >>> cars_gbm.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=train,\n",
            " |      ...                validation_frame=valid)\n",
            " |      >>> cars_gbm.scoring_history()\n",
            " |  \n",
            " |  seed\n",
            " |      Seed for pseudo random number generator (if applicable)\n",
            " |      \n",
            " |      Type: ``int``  (default: ``-1``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
            " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
            " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
            " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
            " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
            " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
            " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
            " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
            " |      >>> response = \"IsDepDelayed\"\n",
            " |      >>> train, valid = airlines.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> gbm_w_seed_1 = H2OGradientBoostingEstimator(col_sample_rate=.7,\n",
            " |      ...                                             seed=1234)\n",
            " |      >>> gbm_w_seed_1.train(x=predictors,\n",
            " |      ...                    y=response,\n",
            " |      ...                    training_frame=train,\n",
            " |      ...                    validation_frame=valid)\n",
            " |      >>> print('auc for the 1st model built with a seed:', gbm_w_seed_1.auc(valid=True))\n",
            " |  \n",
            " |  stopping_metric\n",
            " |      Metric to use for early stopping (AUTO: logloss for classification, deviance for regression and anonomaly_score\n",
            " |      for Isolation Forest). Note that custom and custom_increasing can only be used in GBM and DRF with the Python\n",
            " |      client.\n",
            " |      \n",
            " |      One of: ``\"auto\"``, ``\"deviance\"``, ``\"logloss\"``, ``\"mse\"``, ``\"rmse\"``, ``\"mae\"``, ``\"rmsle\"``, ``\"auc\"``,\n",
            " |      ``\"aucpr\"``, ``\"lift_top_group\"``, ``\"misclassification\"``, ``\"mean_per_class_error\"``, ``\"custom\"``,\n",
            " |      ``\"custom_increasing\"``  (default: ``\"auto\"``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
            " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
            " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
            " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
            " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
            " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
            " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
            " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
            " |      >>> response = \"IsDepDelayed\"\n",
            " |      >>> train, valid = airlines.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> airlines_gbm = H2OGradientBoostingEstimator(stopping_metric=\"auc\",\n",
            " |      ...                                             stopping_rounds=3,\n",
            " |      ...                                             stopping_tolerance=1e-2,\n",
            " |      ...                                             seed=1234)\n",
            " |      >>> airlines_gbm.train(x=predictors,\n",
            " |      ...                    y=response,\n",
            " |      ...                    training_frame=train,\n",
            " |      ...                    validation_frame=valid)\n",
            " |      >>> airlines_gbm.auc(valid=True)\n",
            " |  \n",
            " |  stopping_rounds\n",
            " |      Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the\n",
            " |      stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable)\n",
            " |      \n",
            " |      Type: ``int``  (default: ``0``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
            " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
            " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
            " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
            " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
            " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
            " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
            " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
            " |      >>> response = \"IsDepDelayed\"\n",
            " |      >>> train, valid = airlines.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> airlines_gbm = H2OGradientBoostingEstimator(stopping_metric=\"auc\",\n",
            " |      ...                                             stopping_rounds=3,\n",
            " |      ...                                             stopping_tolerance=1e-2,\n",
            " |      ...                                             seed=1234)\n",
            " |      >>> airlines_gbm.train(x=predictors,\n",
            " |      ...                    y=response,\n",
            " |      ...                    training_frame=train,\n",
            " |      ...                    validation_frame=valid)\n",
            " |      >>> airlines_gbm.auc(valid=True)\n",
            " |  \n",
            " |  stopping_tolerance\n",
            " |      Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this much)\n",
            " |      \n",
            " |      Type: ``float``  (default: ``0.001``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> airlines= h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/airlines/allyears2k_headers.zip\")\n",
            " |      >>> airlines[\"Year\"] = airlines[\"Year\"].asfactor()\n",
            " |      >>> airlines[\"Month\"] = airlines[\"Month\"].asfactor()\n",
            " |      >>> airlines[\"DayOfWeek\"] = airlines[\"DayOfWeek\"].asfactor()\n",
            " |      >>> airlines[\"Cancelled\"] = airlines[\"Cancelled\"].asfactor()\n",
            " |      >>> airlines['FlightNum'] = airlines['FlightNum'].asfactor()\n",
            " |      >>> predictors = [\"Origin\", \"Dest\", \"Year\", \"UniqueCarrier\",\n",
            " |      ...               \"DayOfWeek\", \"Month\", \"Distance\", \"FlightNum\"]\n",
            " |      >>> response = \"IsDepDelayed\"\n",
            " |      >>> train, valid= airlines.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> airlines_gbm = H2OGradientBoostingEstimator(stopping_metric=\"auc\",\n",
            " |      ...                                             stopping_rounds=3,\n",
            " |      ...                                             stopping_tolerance=1e-2,\n",
            " |      ...                                             seed=1234)\n",
            " |      >>> airlines_gbm.train(x=predictors,\n",
            " |      ...                    y=response,\n",
            " |      ...                    training_frame=train,\n",
            " |      ...                    validation_frame=valid)\n",
            " |      >>> airlines_gbm.auc(valid=True)\n",
            " |  \n",
            " |  training_frame\n",
            " |      Id of the training data frame.\n",
            " |      \n",
            " |      Type: ``H2OFrame``.\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
            " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
            " |      >>> response = \"economy_20mpg\"\n",
            " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(seed=1234)\n",
            " |      >>> cars_gbm.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=train,\n",
            " |      ...                validation_frame=valid)\n",
            " |      >>> cars_gbm.auc(valid=True)\n",
            " |  \n",
            " |  tweedie_power\n",
            " |      Tweedie power for Tweedie regression, must be between 1 and 2.\n",
            " |      \n",
            " |      Type: ``float``  (default: ``1.5``).\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> insurance = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/glm_test/insurance.csv\")\n",
            " |      >>> predictors = insurance.columns[0:4]\n",
            " |      >>> response = 'Claims'\n",
            " |      >>> insurance['Group'] = insurance['Group'].asfactor()\n",
            " |      >>> insurance['Age'] = insurance['Age'].asfactor()\n",
            " |      >>> train, valid = insurance.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> insurance_gbm = H2OGradientBoostingEstimator(distribution=\"tweedie\",\n",
            " |      ...                                              tweedie_power=1.2,\n",
            " |      ...                                              seed=1234)\n",
            " |      >>> insurance_gbm.train(x=predictors,\n",
            " |      ...                     y=response,\n",
            " |      ...                     training_frame=train,\n",
            " |      ...                     validation_frame=valid)\n",
            " |      >>> insurance_gbm.mse(valid=True)\n",
            " |  \n",
            " |  validation_frame\n",
            " |      Id of the validation data frame.\n",
            " |      \n",
            " |      Type: ``H2OFrame``.\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
            " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
            " |      >>> response = \"economy_20mpg\"\n",
            " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(seed=1234)\n",
            " |      >>> cars_gbm.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=train,\n",
            " |      ...                validation_frame=valid)\n",
            " |      >>> cars_gbm.auc(valid=True)\n",
            " |  \n",
            " |  weights_column\n",
            " |      Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from the\n",
            " |      dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative\n",
            " |      weights are not allowed. Note: Weights are per-row observation weights and do not increase the size of the data\n",
            " |      frame. This is typically the number of times a row is repeated, but non-integer values are supported as well.\n",
            " |      During training, rows with higher weights matter more, due to the larger loss function pre-factor.\n",
            " |      \n",
            " |      Type: ``str``.\n",
            " |      \n",
            " |      :examples:\n",
            " |      \n",
            " |      >>> cars = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/junit/cars_20mpg.csv\")\n",
            " |      >>> cars[\"economy_20mpg\"] = cars[\"economy_20mpg\"].asfactor()\n",
            " |      >>> predictors = [\"displacement\",\"power\",\"weight\",\"acceleration\",\"year\"]\n",
            " |      >>> response = \"economy_20mpg\"\n",
            " |      >>> train, valid = cars.split_frame(ratios=[.8], seed=1234)\n",
            " |      >>> cars_gbm = H2OGradientBoostingEstimator(seed=1234)\n",
            " |      >>> cars_gbm.train(x=predictors,\n",
            " |      ...                y=response,\n",
            " |      ...                training_frame=train,\n",
            " |      ...                validation_frame=valid,\n",
            " |      ...                weights_column=\"weight\")\n",
            " |      >>> cars_gbm.auc(valid=True)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  algo = 'gbm'\n",
            " |  \n",
            " |  param_names = {'balance_classes', 'build_tree_one_node', 'calibrate_mo...\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
            " |  \n",
            " |  convert_H2OXGBoostParams_2_XGBoostParams(self)\n",
            " |      In order to use convert_H2OXGBoostParams_2_XGBoostParams and convert_H2OFrame_2_DMatrix, you must import\n",
            " |      the following toolboxes: xgboost, pandas, numpy and scipy.sparse.\n",
            " |      \n",
            " |      Given an H2OXGBoost model, this method will generate the corresponding parameters that should be used by\n",
            " |      native XGBoost in order to give exactly the same result, assuming that the same dataset\n",
            " |      (derived from h2oFrame) is used to train the native XGBoost model.\n",
            " |      \n",
            " |      Follow the steps below to compare H2OXGBoost and native XGBoost:\n",
            " |      \n",
            " |       1. Train the H2OXGBoost model with H2OFrame trainFile and generate a prediction:\n",
            " |      \n",
            " |        - h2oModelD = H2OXGBoostEstimator(\\*\\*h2oParamsD) # parameters specified as a dict()\n",
            " |        - h2oModelD.train(x=myX, y=y, training_frame=trainFile) # train with H2OFrame trainFile\n",
            " |        - h2oPredict = h2oPredictD = h2oModelD.predict(trainFile)\n",
            " |      \n",
            " |       2. Derive the DMatrix from H2OFrame:\n",
            " |       \n",
            " |        - nativeDMatrix = trainFile.convert_H2OFrame_2_DMatrix(myX, y, h2oModelD)\n",
            " |      \n",
            " |       3. Derive the parameters for native XGBoost:\n",
            " |       \n",
            " |        - nativeParams = h2oModelD.convert_H2OXGBoostParams_2_XGBoostParams()\n",
            " |      \n",
            " |       4. Train your native XGBoost model and generate a prediction:\n",
            " |       \n",
            " |        - nativeModel = xgb.train(params=nativeParams[0], dtrain=nativeDMatrix, num_boost_round=nativeParams[1])\n",
            " |        - nativePredict = nativeModel.predict(data=nativeDMatrix, ntree_limit=nativeParams[1]\n",
            " |      \n",
            " |       5. Compare the predictions h2oPredict from H2OXGBoost, nativePredict from native XGBoost.\n",
            " |      \n",
            " |      :return: nativeParams, num_boost_round\n",
            " |  \n",
            " |  fit(self, X, y=None, **params)\n",
            " |      Fit an H2O model as part of a scikit-learn pipeline or grid search.\n",
            " |      \n",
            " |      A warning will be issued if a caller other than sklearn attempts to use this method.\n",
            " |      \n",
            " |      :param H2OFrame X: An H2OFrame consisting of the predictor variables.\n",
            " |      :param H2OFrame y: An H2OFrame consisting of the response variable.\n",
            " |      :param params: Extra arguments.\n",
            " |      :returns: The current instance of H2OEstimator for method chaining.\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Obtain parameters for this estimator.\n",
            " |      \n",
            " |      Used primarily for sklearn Pipelines and sklearn grid search.\n",
            " |      \n",
            " |      :param deep: If True, return parameters of all sub-objects that are estimators.\n",
            " |      \n",
            " |      :returns: A dict of parameters\n",
            " |  \n",
            " |  join(self)\n",
            " |      Wait until job's completion.\n",
            " |  \n",
            " |  set_params(self, **parms)\n",
            " |      Used by sklearn for updating parameters during grid search.\n",
            " |      \n",
            " |      :param parms: A dictionary of parameters that will be set on this model.\n",
            " |      :returns: self, the current estimator object with the parameters all set as desired.\n",
            " |  \n",
            " |  start(self, x, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, **params)\n",
            " |      Train the model asynchronously (to block for results call :meth:`join`).\n",
            " |      \n",
            " |      :param x: A list of column names or indices indicating the predictor columns.\n",
            " |      :param y: An index or a column name indicating the response column.\n",
            " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
            " |          additional columns specified by fold, offset, and weights).\n",
            " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
            " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
            " |          assignments.\n",
            " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
            " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
            " |  \n",
            " |  train(self, x=None, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, max_runtime_secs=None, ignored_columns=None, model_id=None, verbose=False)\n",
            " |      Train the H2O model.\n",
            " |      \n",
            " |      :param x: A list of column names or indices indicating the predictor columns.\n",
            " |      :param y: An index or a column name indicating the response column.\n",
            " |      :param H2OFrame training_frame: The H2OFrame having the columns indicated by x and y (as well as any\n",
            " |          additional columns specified by fold, offset, and weights).\n",
            " |      :param offset_column: The name or index of the column in training_frame that holds the offsets.\n",
            " |      :param fold_column: The name or index of the column in training_frame that holds the per-row fold\n",
            " |          assignments.\n",
            " |      :param weights_column: The name or index of the column in training_frame that holds the per-row weights.\n",
            " |      :param validation_frame: H2OFrame with validation data to be scored on while training.\n",
            " |      :param float max_runtime_secs: Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
            " |      :param bool verbose: Print scoring history to stdout. Defaults to False.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
            " |  \n",
            " |  mixin(obj, cls)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from h2o.model.model_base.ModelBase:\n",
            " |  \n",
            " |  __getattr__(self, name)\n",
            " |  \n",
            " |  __repr__(self)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  aic(self, train=False, valid=False, xval=False)\n",
            " |      Get the AIC (Akaike Information Criterium).\n",
            " |      \n",
            " |      If all are False (default), then return the training metric value.\n",
            " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
            " |      \"valid\", and \"xval\".\n",
            " |      \n",
            " |      :param bool train: If train is True, then return the AIC value for the training data.\n",
            " |      :param bool valid: If valid is True, then return the AIC value for the validation data.\n",
            " |      :param bool xval:  If xval is True, then return the AIC value for the validation data.\n",
            " |      \n",
            " |      :returns: The AIC.\n",
            " |  \n",
            " |  auc(self, train=False, valid=False, xval=False)\n",
            " |      Get the AUC (Area Under Curve).\n",
            " |      \n",
            " |      If all are False (default), then return the training metric value.\n",
            " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
            " |      \"valid\", and \"xval\".\n",
            " |      \n",
            " |      :param bool train: If train is True, then return the AUC value for the training data.\n",
            " |      :param bool valid: If valid is True, then return the AUC value for the validation data.\n",
            " |      :param bool xval:  If xval is True, then return the AUC value for the validation data.\n",
            " |      \n",
            " |      :returns: The AUC.\n",
            " |  \n",
            " |  aucpr(self, train=False, valid=False, xval=False)\n",
            " |      Get the aucPR (Area Under PRECISION RECALL Curve).\n",
            " |      \n",
            " |      If all are False (default), then return the training metric value.\n",
            " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
            " |      \"valid\", and \"xval\".\n",
            " |      \n",
            " |      :param bool train: If train is True, then return the aucpr value for the training data.\n",
            " |      :param bool valid: If valid is True, then return the aucpr value for the validation data.\n",
            " |      :param bool xval:  If xval is True, then return the aucpr value for the validation data.\n",
            " |      \n",
            " |      :returns: The aucpr.\n",
            " |  \n",
            " |  biases(self, vector_id=0)\n",
            " |      Return the frame for the respective bias vector.\n",
            " |      \n",
            " |      :param: vector_id: an integer, ranging from 0 to number of layers, that specifies the bias vector to return.\n",
            " |      \n",
            " |      :returns: an H2OFrame which represents the bias vector identified by vector_id\n",
            " |  \n",
            " |  catoffsets(self)\n",
            " |      Categorical offsets for one-hot encoding.\n",
            " |  \n",
            " |  coef(self)\n",
            " |      Return the coefficients which can be applied to the non-standardized data.\n",
            " |      \n",
            " |      Note: standardize = True by default, if set to False then coef() return the coefficients which are fit directly.\n",
            " |  \n",
            " |  coef_norm(self)\n",
            " |      Return coefficients fitted on the standardized data (requires standardize = True, which is on by default).\n",
            " |      \n",
            " |      These coefficients can be used to evaluate variable importance.\n",
            " |  \n",
            " |  cross_validation_fold_assignment(self)\n",
            " |      Obtain the cross-validation fold assignment for all rows in the training data.\n",
            " |      \n",
            " |      :returns: H2OFrame\n",
            " |  \n",
            " |  cross_validation_holdout_predictions(self)\n",
            " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on the training data.\n",
            " |      \n",
            " |      This is equivalent to summing up all H2OFrames returned by cross_validation_predictions.\n",
            " |      \n",
            " |      :returns: H2OFrame\n",
            " |  \n",
            " |  cross_validation_metrics_summary(self)\n",
            " |      Retrieve Cross-Validation Metrics Summary.\n",
            " |      \n",
            " |      :returns: The cross-validation metrics summary as an H2OTwoDimTable\n",
            " |  \n",
            " |  cross_validation_models(self)\n",
            " |      Obtain a list of cross-validation models.\n",
            " |      \n",
            " |      :returns: list of H2OModel objects.\n",
            " |  \n",
            " |  cross_validation_predictions(self)\n",
            " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on their holdout data.\n",
            " |      \n",
            " |      Note that the predictions are expanded to the full number of rows of the training data, with 0 fill-in.\n",
            " |      \n",
            " |      :returns: list of H2OFrame objects.\n",
            " |  \n",
            " |  deepfeatures(self, test_data, layer)\n",
            " |      Return hidden layer details.\n",
            " |      \n",
            " |      :param test_data: Data to create a feature space on\n",
            " |      :param layer: 0 index hidden layer\n",
            " |  \n",
            " |  detach(self)\n",
            " |      Detach the Python object from the backend, usually by clearing its key\n",
            " |  \n",
            " |  download_mojo(self, path='.', get_genmodel_jar=False, genmodel_name='')\n",
            " |      Download the model in MOJO format.\n",
            " |      \n",
            " |      :param path: the path where MOJO file should be saved.\n",
            " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
            " |      :param genmodel_name: Custom name of genmodel jar\n",
            " |      :returns: name of the MOJO file written.\n",
            " |  \n",
            " |  download_pojo(self, path='', get_genmodel_jar=False, genmodel_name='')\n",
            " |      Download the POJO for this model to the directory specified by path.\n",
            " |      \n",
            " |      If path is an empty string, then dump the output to screen.\n",
            " |      \n",
            " |      :param path:  An absolute path to the directory where POJO should be saved.\n",
            " |      :param get_genmodel_jar: if True, then also download h2o-genmodel.jar and store it in folder ``path``.\n",
            " |      :param genmodel_name: Custom name of genmodel jar\n",
            " |      :returns: name of the POJO file written.\n",
            " |  \n",
            " |  feature_frequencies(self, test_data)\n",
            " |      Retrieve the number of occurrences of each feature for given observations \n",
            " |      on their respective paths in a tree ensemble model.\n",
            " |      Available for GBM, Random Forest and Isolation Forest models.\n",
            " |      \n",
            " |      :param H2OFrame test_data: Data on which to calculate feature frequencies.\n",
            " |      \n",
            " |      :returns: A new H2OFrame made of feature contributions.\n",
            " |  \n",
            " |  get_xval_models(self, key=None)\n",
            " |      Return a Model object.\n",
            " |      \n",
            " |      :param key: If None, return all cross-validated models; otherwise return the model that key points to.\n",
            " |      \n",
            " |      :returns: A model or list of models.\n",
            " |  \n",
            " |  gini(self, train=False, valid=False, xval=False)\n",
            " |      Get the Gini coefficient.\n",
            " |      \n",
            " |      If all are False (default), then return the training metric value.\n",
            " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
            " |      \"valid\", and \"xval\"\n",
            " |      \n",
            " |      :param bool train: If train is True, then return the Gini Coefficient value for the training data.\n",
            " |      :param bool valid: If valid is True, then return the Gini Coefficient value for the validation data.\n",
            " |      :param bool xval:  If xval is True, then return the Gini Coefficient value for the cross validation data.\n",
            " |      \n",
            " |      :returns: The Gini Coefficient for this binomial model.\n",
            " |  \n",
            " |  is_cross_validated(self)\n",
            " |      Return True if the model was cross-validated.\n",
            " |  \n",
            " |  logloss(self, train=False, valid=False, xval=False)\n",
            " |      Get the Log Loss.\n",
            " |      \n",
            " |      If all are False (default), then return the training metric value.\n",
            " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
            " |      \"valid\", and \"xval\".\n",
            " |      \n",
            " |      :param bool train: If train is True, then return the log loss value for the training data.\n",
            " |      :param bool valid: If valid is True, then return the log loss value for the validation data.\n",
            " |      :param bool xval:  If xval is True, then return the log loss value for the cross validation data.\n",
            " |      \n",
            " |      :returns: The log loss for this regression model.\n",
            " |  \n",
            " |  mae(self, train=False, valid=False, xval=False)\n",
            " |      Get the Mean Absolute Error.\n",
            " |      \n",
            " |      If all are False (default), then return the training metric value.\n",
            " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
            " |      \"valid\", and \"xval\".\n",
            " |      \n",
            " |      :param bool train: If train is True, then return the MAE value for the training data.\n",
            " |      :param bool valid: If valid is True, then return the MAE value for the validation data.\n",
            " |      :param bool xval:  If xval is True, then return the MAE value for the cross validation data.\n",
            " |      \n",
            " |      :returns: The MAE for this regression model.\n",
            " |  \n",
            " |  mean_residual_deviance(self, train=False, valid=False, xval=False)\n",
            " |      Get the Mean Residual Deviances.\n",
            " |      \n",
            " |      If all are False (default), then return the training metric value.\n",
            " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
            " |      \"valid\", and \"xval\".\n",
            " |      \n",
            " |      :param bool train: If train is True, then return the Mean Residual Deviance value for the training data.\n",
            " |      :param bool valid: If valid is True, then return the Mean Residual Deviance value for the validation data.\n",
            " |      :param bool xval:  If xval is True, then return the Mean Residual Deviance value for the cross validation data.\n",
            " |      \n",
            " |      :returns: The Mean Residual Deviance for this regression model.\n",
            " |  \n",
            " |  model_performance(self, test_data=None, train=False, valid=False, xval=False)\n",
            " |      Generate model metrics for this model on test_data.\n",
            " |      \n",
            " |      :param H2OFrame test_data: Data set for which model metrics shall be computed against. All three of train,\n",
            " |          valid and xval arguments are ignored if test_data is not None.\n",
            " |      :param bool train: Report the training metrics for the model.\n",
            " |      :param bool valid: Report the validation metrics for the model.\n",
            " |      :param bool xval: Report the cross-validation metrics for the model. If train and valid are True, then it\n",
            " |          defaults to True.\n",
            " |      \n",
            " |      :returns: An object of class H2OModelMetrics.\n",
            " |  \n",
            " |  mse(self, train=False, valid=False, xval=False)\n",
            " |      Get the Mean Square Error.\n",
            " |      \n",
            " |      If all are False (default), then return the training metric value.\n",
            " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
            " |      \"valid\", and \"xval\".\n",
            " |      \n",
            " |      :param bool train: If train is True, then return the MSE value for the training data.\n",
            " |      :param bool valid: If valid is True, then return the MSE value for the validation data.\n",
            " |      :param bool xval:  If xval is True, then return the MSE value for the cross validation data.\n",
            " |      \n",
            " |      :returns: The MSE for this regression model.\n",
            " |  \n",
            " |  normmul(self)\n",
            " |      Normalization/Standardization multipliers for numeric predictors.\n",
            " |  \n",
            " |  normsub(self)\n",
            " |      Normalization/Standardization offsets for numeric predictors.\n",
            " |  \n",
            " |  ntrees_actual(self)\n",
            " |      Returns actual number of trees in a tree model. If early stopping enabled, GBM can reset the ntrees value.\n",
            " |      In this case, the actual ntrees value is less than the original ntrees value a user set before\n",
            " |      building the model.\n",
            " |      \n",
            " |      Type: ``float``\n",
            " |  \n",
            " |  null_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
            " |      Retreive the null degress of freedom if this model has the attribute, or None otherwise.\n",
            " |      \n",
            " |      :param bool train: Get the null dof for the training set. If both train and valid are False, then train is\n",
            " |          selected by default.\n",
            " |      :param bool valid: Get the null dof for the validation set. If both train and valid are True, then train is\n",
            " |          selected by default.\n",
            " |      \n",
            " |      :returns: Return the null dof, or None if it is not present.\n",
            " |  \n",
            " |  null_deviance(self, train=False, valid=False, xval=False)\n",
            " |      Retreive the null deviance if this model has the attribute, or None otherwise.\n",
            " |      \n",
            " |      :param bool train: Get the null deviance for the training set. If both train and valid are False, then train\n",
            " |          is selected by default.\n",
            " |      :param bool valid: Get the null deviance for the validation set. If both train and valid are True, then train\n",
            " |          is selected by default.\n",
            " |      \n",
            " |      :returns: Return the null deviance, or None if it is not present.\n",
            " |  \n",
            " |  partial_plot(self, data, cols=None, destination_key=None, nbins=20, weight_column=None, plot=True, plot_stddev=True, figsize=(7, 10), server=False, include_na=False, user_splits=None, col_pairs_2dpdp=None, save_to_file=None, row_index=None)\n",
            " |      Create partial dependence plot which gives a graphical depiction of the marginal effect of a variable on the\n",
            " |      response. The effect of a variable is measured in change in the mean response.\n",
            " |      \n",
            " |      :param H2OFrame data: An H2OFrame object used for scoring and constructing the plot.\n",
            " |      :param cols: Feature(s) for which partial dependence will be calculated.\n",
            " |      :param destination_key: An key reference to the created partial dependence tables in H2O.\n",
            " |      :param nbins: Number of bins used. For categorical columns make sure the number of bins exceed the level count. If you enable add_missing_NA, the returned length will be nbin+1.\n",
            " |      :param weight_column: A string denoting which column of data should be used as the weight column.\n",
            " |      :param plot: A boolean specifying whether to plot partial dependence table.\n",
            " |      :param plot_stddev: A boolean specifying whether to add std err to partial dependence plot.\n",
            " |      :param figsize: Dimension/size of the returning plots, adjust to fit your output cells.\n",
            " |      :param server: Specify whether to activate matplotlib \"server\" mode. In this case, the plots are saved to a file instead of being rendered.\n",
            " |      :param include_na: A boolean specifying whether missing value should be included in the Feature values.\n",
            " |      :param user_splits: a dictionary containing column names as key and user defined split values as value in a list.\n",
            " |      :param col_pairs_2dpdp: list containing pairs of column names for 2D pdp\n",
            " |      :param save_to_file: Fully qualified name to an image file the resulting plot should be saved to, e.g. '/home/user/pdpplot.png'. The 'png' postfix might be omitted. If the file already exists, it will be overridden. Plot is only saved if plot = True.\n",
            " |      :param row_index: Row for which partial dependence will be calculated instead of the whole input frame.\n",
            " |      :returns: Plot and list of calculated mean response tables for each feature requested.\n",
            " |  \n",
            " |  pprint_coef(self)\n",
            " |      Pretty print the coefficents table (includes normalized coefficients).\n",
            " |  \n",
            " |  pr_auc(self, train=False, valid=False, xval=False)\n",
            " |      ModelBase.pr_auc is deprecated, please use ``ModelBase.aucpr`` instead.\n",
            " |  \n",
            " |  predict(self, test_data, custom_metric=None, custom_metric_func=None)\n",
            " |      Predict on a dataset.\n",
            " |      \n",
            " |      :param H2OFrame test_data: Data on which to make predictions.\n",
            " |      :param custom_metric:  custom evaluation function defined as class reference, the class get uploaded\n",
            " |          into the cluster\n",
            " |      :param custom_metric_func: custom evaluation function reference, e.g, result of upload_custom_metric\n",
            " |      \n",
            " |      :returns: A new H2OFrame of predictions.\n",
            " |  \n",
            " |  predict_contributions(self, test_data)\n",
            " |      Predict feature contributions - SHAP values on an H2O Model (only GBM and XGBoost models).\n",
            " |      \n",
            " |      Returned H2OFrame has shape (#rows, #features + 1) - there is a feature contribution column for each input\n",
            " |      feature, the last column is the model bias (same value for each row). The sum of the feature contributions\n",
            " |      and the bias term is equal to the raw prediction of the model. Raw prediction of tree-based model is the sum \n",
            " |      of the predictions of the individual trees before before the inverse link function is applied to get the actual\n",
            " |      prediction. For Gaussian distribution the sum of the contributions is equal to the model prediction. \n",
            " |      \n",
            " |      Note: Multinomial classification models are currently not supported.\n",
            " |      \n",
            " |      :param H2OFrame test_data: Data on which to calculate contributions.\n",
            " |      \n",
            " |      :returns: A new H2OFrame made of feature contributions.\n",
            " |  \n",
            " |  predict_leaf_node_assignment(self, test_data, type='Path')\n",
            " |      Predict on a dataset and return the leaf node assignment (only for tree-based models).\n",
            " |      \n",
            " |      :param H2OFrame test_data: Data on which to make predictions.\n",
            " |      :param Enum type: How to identify the leaf node. Nodes can be either identified by a path from to the root node\n",
            " |          of the tree to the node or by H2O's internal node id. One of: ``\"Path\"``, ``\"Node_ID\"`` (default: ``\"Path\"``).\n",
            " |      \n",
            " |      :returns: A new H2OFrame of predictions.\n",
            " |  \n",
            " |  r2(self, train=False, valid=False, xval=False)\n",
            " |      Return the R squared for this regression model.\n",
            " |      \n",
            " |      Will return R^2 for GLM Models and will return NaN otherwise.\n",
            " |      \n",
            " |      The R^2 value is defined to be 1 - MSE/var, where var is computed as sigma*sigma.\n",
            " |      \n",
            " |      If all are False (default), then return the training metric value.\n",
            " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
            " |      \"valid\", and \"xval\".\n",
            " |      \n",
            " |      :param bool train: If train is True, then return the R^2 value for the training data.\n",
            " |      :param bool valid: If valid is True, then return the R^2 value for the validation data.\n",
            " |      :param bool xval:  If xval is True, then return the R^2 value for the cross validation data.\n",
            " |      \n",
            " |      :returns: The R squared for this regression model.\n",
            " |  \n",
            " |  residual_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
            " |      Retreive the residual degress of freedom if this model has the attribute, or None otherwise.\n",
            " |      \n",
            " |      :param bool train: Get the residual dof for the training set. If both train and valid are False, then train\n",
            " |          is selected by default.\n",
            " |      :param bool valid: Get the residual dof for the validation set. If both train and valid are True, then train\n",
            " |          is selected by default.\n",
            " |      \n",
            " |      :returns: Return the residual dof, or None if it is not present.\n",
            " |  \n",
            " |  residual_deviance(self, train=False, valid=False, xval=None)\n",
            " |      Retreive the residual deviance if this model has the attribute, or None otherwise.\n",
            " |      \n",
            " |      :param bool train: Get the residual deviance for the training set. If both train and valid are False, then\n",
            " |          train is selected by default.\n",
            " |      :param bool valid: Get the residual deviance for the validation set. If both train and valid are True, then\n",
            " |          train is selected by default.\n",
            " |      \n",
            " |      :returns: Return the residual deviance, or None if it is not present.\n",
            " |  \n",
            " |  respmul(self)\n",
            " |      Normalization/Standardization multipliers for numeric response.\n",
            " |  \n",
            " |  respsub(self)\n",
            " |      Normalization/Standardization offsets for numeric response.\n",
            " |  \n",
            " |  rmse(self, train=False, valid=False, xval=False)\n",
            " |      Get the Root Mean Square Error.\n",
            " |      \n",
            " |      If all are False (default), then return the training metric value.\n",
            " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
            " |      \"valid\", and \"xval\".\n",
            " |      \n",
            " |      :param bool train: If train is True, then return the RMSE value for the training data.\n",
            " |      :param bool valid: If valid is True, then return the RMSE value for the validation data.\n",
            " |      :param bool xval:  If xval is True, then return the RMSE value for the cross validation data.\n",
            " |      \n",
            " |      :returns: The RMSE for this regression model.\n",
            " |  \n",
            " |  rmsle(self, train=False, valid=False, xval=False)\n",
            " |      Get the Root Mean Squared Logarithmic Error.\n",
            " |      \n",
            " |      If all are False (default), then return the training metric value.\n",
            " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
            " |      \"valid\", and \"xval\".\n",
            " |      \n",
            " |      :param bool train: If train is True, then return the RMSLE value for the training data.\n",
            " |      :param bool valid: If valid is True, then return the RMSLE value for the validation data.\n",
            " |      :param bool xval:  If xval is True, then return the RMSLE value for the cross validation data.\n",
            " |      \n",
            " |      :returns: The RMSLE for this regression model.\n",
            " |  \n",
            " |  rotation(self)\n",
            " |      Obtain the rotations (eigenvectors) for a PCA model\n",
            " |      \n",
            " |      :return: H2OFrame\n",
            " |  \n",
            " |  save_model_details(self, path='', force=False)\n",
            " |      Save Model Details of an H2O Model in JSON Format to disk.\n",
            " |      \n",
            " |      :param model: The model object to save.\n",
            " |      :param path: a path to save the model details at (hdfs, s3, local)\n",
            " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
            " |      \n",
            " |      :returns str: the path of the saved model details\n",
            " |  \n",
            " |  save_mojo(self, path='', force=False)\n",
            " |      Save an H2O Model as MOJO (Model Object, Optimized) to disk.\n",
            " |      \n",
            " |      :param model: The model object to save.\n",
            " |      :param path: a path to save the model at (hdfs, s3, local)\n",
            " |      :param force: if True overwrite destination directory in case it exists, or throw exception if set to False.\n",
            " |      \n",
            " |      :returns str: the path of the saved model\n",
            " |  \n",
            " |  score_history(self)\n",
            " |      DEPRECATED. Use :meth:`scoring_history` instead.\n",
            " |  \n",
            " |  scoring_history(self)\n",
            " |      Retrieve Model Score History.\n",
            " |      \n",
            " |      :returns: The score history as an H2OTwoDimTable or a Pandas DataFrame.\n",
            " |  \n",
            " |  show(self)\n",
            " |      Print innards of model, without regards to type.\n",
            " |  \n",
            " |  staged_predict_proba(self, test_data)\n",
            " |      Predict class probabilities at each stage of an H2O Model (only GBM models).\n",
            " |      \n",
            " |      The output structure is analogous to the output of function predict_leaf_node_assignment. For each tree t and\n",
            " |      class c there will be a column Tt.Cc (eg. T3.C1 for tree 3 and class 1). The value will be the corresponding\n",
            " |      predicted probability of this class by combining the raw contributions of trees T1.Cc,..,TtCc. Binomial models\n",
            " |      build the trees just for the first class and values in columns Tx.C1 thus correspond to the the probability p0.\n",
            " |      \n",
            " |      :param H2OFrame test_data: Data on which to make predictions.\n",
            " |      \n",
            " |      :returns: A new H2OFrame of staged predictions.\n",
            " |  \n",
            " |  std_coef_plot(self, num_of_features=None, server=False)\n",
            " |      Plot a GLM model\"s standardized coefficient magnitudes.\n",
            " |      \n",
            " |      :param num_of_features: the number of features shown in the plot.\n",
            " |      :param server: ?\n",
            " |      \n",
            " |      :returns: None.\n",
            " |  \n",
            " |  summary(self)\n",
            " |      Print a detailed summary of the model.\n",
            " |  \n",
            " |  training_model_metrics(self)\n",
            " |      Return training model metrics for any model.\n",
            " |  \n",
            " |  varimp(self, use_pandas=False)\n",
            " |      Pretty print the variable importances, or return them in a list.\n",
            " |      \n",
            " |      :param bool use_pandas: If True, then the variable importances will be returned as a pandas data frame.\n",
            " |      \n",
            " |      :returns: A list or Pandas DataFrame.\n",
            " |  \n",
            " |  varimp_plot(self, num_of_features=None, server=False)\n",
            " |      Plot the variable importance for a trained model.\n",
            " |      \n",
            " |      :param num_of_features: the number of features shown in the plot (default is 10 or all if less than 10).\n",
            " |      :param server: ?\n",
            " |      \n",
            " |      :returns: None.\n",
            " |  \n",
            " |  weights(self, matrix_id=0)\n",
            " |      Return the frame for the respective weight matrix.\n",
            " |      \n",
            " |      :param matrix_id: an integer, ranging from 0 to number of layers, that specifies the weight matrix to return.\n",
            " |      \n",
            " |      :returns: an H2OFrame which represents the weight matrix identified by matrix_id\n",
            " |  \n",
            " |  xval_keys(self)\n",
            " |      Return model keys for the cross-validated model.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from h2o.model.model_base.ModelBase:\n",
            " |  \n",
            " |  actual_params\n",
            " |      Dictionary of actual parameters of the model.\n",
            " |  \n",
            " |  default_params\n",
            " |      Dictionary of the default parameters of the model.\n",
            " |  \n",
            " |  end_time\n",
            " |      Timestamp (milliseconds since 1970) when the model training was ended.\n",
            " |  \n",
            " |  full_parameters\n",
            " |      Dictionary of the full specification of all parameters.\n",
            " |  \n",
            " |  have_mojo\n",
            " |      True, if export to MOJO is possible\n",
            " |  \n",
            " |  have_pojo\n",
            " |      True, if export to POJO is possible\n",
            " |  \n",
            " |  key\n",
            " |      :return: the unique key representing the object on the backend\n",
            " |  \n",
            " |  model_id\n",
            " |      Model identifier.\n",
            " |  \n",
            " |  params\n",
            " |      Get the parameters and the actual/default values only.\n",
            " |      \n",
            " |      :returns: A dictionary of parameters used to build this model.\n",
            " |  \n",
            " |  run_time\n",
            " |      Model training time in milliseconds\n",
            " |  \n",
            " |  start_time\n",
            " |      Timestamp (milliseconds since 1970) when the model training was started.\n",
            " |  \n",
            " |  type\n",
            " |      The type of model built: ``\"classifier\"`` or ``\"regressor\"`` or ``\"unsupervised\"``\n",
            " |  \n",
            " |  xvals\n",
            " |      Return a list of the cross-validated models.\n",
            " |      \n",
            " |      :returns: A list of models.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from h2o.base.Keyed:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mon-H1vBCUxK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}